<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: RNN | 乐者为王]]></title>
  <link href="http://codemany.com/tags/rnn/atom.xml" rel="self"/>
  <link href="http://codemany.com/"/>
  <updated>2018-01-08T13:58:36+08:00</updated>
  <id>http://codemany.com/</id>
  <author>
    <name><![CDATA[dohkoos]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[循环神经网络不可思议的效用]]></title>
    <link href="http://codemany.com/blog/rnn-effectiveness/"/>
    <updated>2018-01-07T09:44:50+08:00</updated>
    <id>http://codemany.com/blog/rnn-effectiveness</id>
    <content type="html"><![CDATA[<p>英文原文：<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></p>

<p>循环神经网络（RNN）是个神奇的东西。我仍然记得我为<a href="http://cs.stanford.edu/people/karpathy/deepimagesent/">图像标注</a>而训练我的首个循环网络的情景。我的第一个幼稚模型（带有相当随意选择的超参数）在经过几十分钟的训练后就开始在图像的有意义的边缘产生非常漂亮的描述。有时候，模型的简单与你从中得到的结果的质量之间的比例超过你的预期，这次就是一个例子。为什么当时这个结果如此令人震惊？普遍的看法是，RNN应该是很难训练的（随着更多的实践，我实际上得到了相反的结论）。在这之后的1年：我一直在训练RNN，并多次见证它们的力量和健壮性，但它们的神奇输出仍然让我感到有趣。这篇文章将与你分享一些RNN的魔法。</p>

<blockquote>
<p>我们将训练RNN让它一个字符一个字符地生成文本，然后思考“这怎么可能？”</p>
</blockquote>

<p>顺便说一句，我会把这篇文章涉及的<a href="https://github.com/karpathy/char-rnn">代码</a>发布到GitHub上，它可以让你基于多层LSTM来训练字符级别的语言模型。你给它输入大量的文本，它将学会生成类似的文本。你也可以用它来复现我下面的实验。那么RNN究竟是什么呢？</p>

<h3 id="循环神经网络">循环神经网络</h3>

<p>序列。Vanilla神经网络（还有卷积网络）最大的局限性在于它的API太受约束：它接受固定大小的向量作为输入（例如图像），然后产生固定大小的向量作为输出（例如不同分类的概率）。不仅如此：这些模型使用固定数量的计算步骤（例如模型中的层数）执行这种映射。循环神经网络如此令人兴奋的主要原因是它允许我们对向量的序列进行操作：输入中的序列、输出中的序列、或者最普遍情况下的输入输出序列。下面是几个具体的示例：</p>

<p><img src="/uploads/diags.jpg" alt="diags"></p>

<p>每个矩形都是一个向量，箭头代表函数（例如矩阵乘法）。输入向量为红色，输出向量为蓝色，绿色向量保持RNN的状态。从左到右是：</p>

<ol>
<li>没有RNN的Vanilla处理模式，从固定大小的输入到固定大小的输出（例如图像分类）。</li>
<li>序列输出（例如图像标注，输入图像然后输出一段文字序列）。</li>
<li>序列输入（例如情感分析，给定的文字被分类为表达正面或者负面情感）。</li>
<li>序列输入和序列输出（例如机器翻译：RNN读取英语句子然后以法语的形式输出）。</li>
<li>同步序列输入和输出（例如视频分类，对视频的每个帧打标签）。</li>
</ol>

<p>注意，每个案例都没有对序列长度进行预先规定，因为循环变换（绿色）是固定的，且根据需要可以多次使用。</p>

<p>正如你预想的那样，与使用固定数量的计算步骤的固定网络相比，序列组织方法的操作要更为强大。RNN通过固定的（但可以学习的）函数把输入向量与其状态向量结合起来以产生新的状态向量。这在编程术语中可以被解释为，运行一个具有某些输入和一些内部变量的固定程序。从这个角度看，RNN本质上是在描述程序。事实上，就它可以模拟任意程序（使用恰当的权值向量）而言，<a href="http://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf">RNN是图灵完备的</a>。但是类似于神经网络的通用近似定理，你不用过于关注其中的细节。</p>

<blockquote>
<p>如果训练Vanilla神经网络是对函数进行优化，那么训练循环网络就是对程序进行优化。</p>
</blockquote>

<p>序列缺失情况下的序列化处理。你可能会想，将序列作为输入或输出是相当少见的，但重要的是要认识到，即使输入或输出是固定向量，仍然可以使用这种强大的形式体系以序列化的方式对它们进行处理。例如，下图显示的结果来自<a href="https://deepmind.com/">DeepMind</a>的两篇非常不错的论文。在左边，算法学习一种循环网络策略，可以将它的注意力集中在图像周围。具体地说，就是它学习从左到右阅读门牌号码（<a href="https://arxiv.org/abs/1412.7755">Ba et al.</a>）。在右边，循环网络通过学习在画布上序列化地添加颜色来生成一张数字图像（<a href="https://arxiv.org/abs/1502.04623">Gregor et al.</a>）。</p>

<p><img src="/uploads/house-read.gif" alt="house-read">
<img src="/uploads/house-generate.gif" alt="house-generate"></p>

<p><em>左边：RNN学习阅读门牌号码。右边：RNN学习绘制门牌号码。</em></p>

<p>言外之意就是，即使数据不是序列的形式，你仍然可以制定和训练出强大的模型来学习序列化地处理它。你正在学习处理固定大小数据的有状态程序。</p>

<p>RNN计算。那么这些是如何工作的呢？主要是RNN有个看似简单的API：它接收输入向量x，然后给出输出向量y。然而最重要的是，该输出向量的内容不仅受到刚才输入的影响，还受到过去整个历史输入的影响。写成类的话，RNN的API由单个step函数构成。</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">rnn = RNN()
y = rnn.step(x)  # x is an input vector, y is the RNN&#39;s output vector
</code></pre></div>
<p>每当step函数被调用时，RNN的有些内部状态就会被更新。在最简单的案例中，这个状态由单个隐藏向量h构成。以下是Vanilla RNN中step函数的实现：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">class RNN:
  # ...
  def step(self, x):
    # update the hidden state
    self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))
    # compute the output vector
    y = np.dot(self.W_hy, self.h)
    return y
</code></pre></div>
<p>上述代码详细说明了vanilla RNN的前向传播。这个RNN的参数是3个矩阵：W_hh、W_xh、W_hy。隐藏状态self.h被初始化为零向量。np.tanh函数实现一个非线性，将激活值压缩到范围[-1, 1]。注意代码是如何工作的：tanh内有两个条件，一是基于前面的隐藏状态，一是基于当前的输入。在NumPy中，np.dot是矩阵乘法。两个中间变量相加，然后被tanh压缩为新的状态向量。如果你更喜欢用数学公式理解，我们也可以将隐藏状态写成：<img src="/uploads/equation.png" alt="equation">。</p>

<p>我们用随机数初始化RNN的矩阵，训练中的大量工作用来寻找那些能够产生期望行为的矩阵，正如用一些损失函数来度量的，这些函数表示对于输入序列x你偏好什么类型的输出y。</p>

<p>深度网络。RNN是神经网络，如果你进行深度学习并且开始像叠煎饼一样堆叠模型，它将会工作得越来越好（如果做得正确的话）。例如，我们可以通过以下方式建立一个2层的循环网络：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">y1 = rnn1.step(x)
y = rnn2.step(y1)
</code></pre></div>
<p>换句话说，我们有两个独立的RNN：一个RNN接收输入向量，而第二个RNN以第一个RNN的输出作为其输入。RNN其实并不关心这些——它们都只是向量的进出，以及在反向传播期间某些梯度流经每个模块。</p>

<p>需要指明的是，在实践中我们大多数人使用略有不同的长短期记忆（LSTM）网络。LSTM是一种特殊类型的循环网络，由于其强大的更新方程和一些吸引人的动态反向传播机制，它在实践中的效果略好一些。除了用于更新计算（self.h=...）的数学形式变得有点复杂外，所有本文介绍的关于RNN的内容都完全相同。从这里开始，我会混合使用术语RNN和LSTM，但是本文中的所有实验都是用LSTM完成的。</p>

<h3 id="字符级别的语言模型">字符级别的语言模型</h3>

<p>现在我们已经知道RNN是什么，为什么它如此令人兴奋，以及它是如何工作的。我们现在就用它来实现一个有趣的应用：我们将训练RNN字符级别的语言模型。也就是说，我们给RNN巨量的文本，然后让其建模，根据序列中以前的字符序列给出下个字符的概率分布。这将允许我们一次一个字符地生成新文本。</p>

<p>作为示例，假设我们拥有只有四个字符“helo”的词汇表，然后想用训练序列“hello”训练一个RNN。这个训练序列实际上是4个独立的训练示例的来源：</p>

<ol>
<li>“h”出现时下个字符最有可能是“e”。</li>
<li>“he”出现时下个字符最有可能是“l”。</li>
<li>“hel”出现时下个字符最有可能是“l”。</li>
<li>“hell”出现时下个字符最有可能是“o”。</li>
</ol>

<p>具体来说，我们会使用1-of-k编码方式（即除对应字符为1外其余都为0）将每个字符编码成一个向量，并且使用step函数将它们一次一个地喂给RNN。然后，我们观察四维输出向量（每个字符一维）序列，我们将其解释为RNN当前分配给序列中下次到来的每个字符的置信度。以下是示意图：</p>

<p><img src="/uploads/charseq.jpg" alt="charseq"></p>

<p>这个RNN示例具有4维输入和输出层，以及3个单位（神经元）的隐藏层。该示意图显示了当RNN把字符“hell”当作输入时前向传播中的激活值。输出层包含RNN为下个字符分配的置信度（词汇表是“h,e,l,o”）。我们希望绿色数值尽可能高，红色数值尽可能低。</p>

<p>例如，我们可以看到，在第1个时间步骤中，当RNN看到字符“h”时，它将下个可能出现字符的置信度分别设成“h”为1，“e”为2.2，“l”为-3.0，“o”为4.1。因为在训练数据（字符串“hello”）中，下个正确的字符是“e”，所以我们希望增加其置信度（绿色）并降低所有其它字符的置信度（红色）。同样，在4个时间步骤中的每个步骤都有理想的目标字符需要网络给予更大的置信度。由于RNN完全由可微分的操作组成，我们可以运行反向传播算法（这只是微积分链式法则的递归应用）以计算出在哪个方向上我们应该调整其每个权重以增加正确目标（绿色粗体数值）的分数。我们然后可以执行参数更新，即在这个梯度方向上微调每个权重。如果我们在参数更新之后将相同的输入喂给RNN，我们会发现正确字符的分数（例如，第一个时间步骤中的“e”）将会略微变高（例如，从2.2变成2.3），而不正确字符的分数将会略微变低。然后我们重复这个过程多次直到网络收敛，并且其预测最终与训练数据一致，即总能正确预测下个字符。</p>

<p>更技术的解释是我们对每个输出向量同时使用标准的Softmax分类器（通常也称为交叉熵损失）。使用迷你批量的随机梯度下降训练RNN，并且我喜欢使用<a href="http://arxiv.org/abs/1502.04390">RMSProp</a>或Adam（每个参数的自适应学习速率方法）来稳定参数的更新。</p>

<p>另外要注意的是，输入字符“l”第一次的目标为“l”，但第二次为“o”。因此，RNN不能单独依赖输入，必须使用其循环连接来跟踪上下文以实现此任务。</p>

<p>在测试时，我们喂给RNN一个字符，并得到下次到来的字符的分布。我们从这个分布中取样，然后将其反馈给RNN以获得下个字符。重复这个过程你就会得到文本！现在让我们在不同的数据集上训练RNN，看看会发生什么。</p>

<p>为了进一步说明，出于教育目的我还写过<a href="https://gist.github.com/karpathy/d4dee566867f8291f086">使用Python/NumPy的最小字符级别的RNN语言模型</a>。它只有大约100行左右，如果你更擅长阅读代码而不是文本，希望它能对上述内容给出一个简洁、具体和有用的总结。现在我们将深入实例结果，它由更高效的Lua/Torch代码库产生。</p>

<h3 id="rnn的乐趣">RNN的乐趣</h3>

<p>以下5个示例的字符模型都使用我在GitHub上发布的<a href="https://github.com/karpathy/char-rnn">代码</a>进行训练。每个案例中的输入都是单个文本文件，我们将训练RNN来预测序列中的下个字符。</p>

<h4 id="paul-graham生成器">Paul Graham生成器</h4>

<p>让我们先尝试用一个小的英文数据集作为完整性检查。我最喜欢的数据集是<a href="http://www.paulgraham.com/articles.html">Paul Graham的文集</a>。基本想法是，这些文章中有很多的智慧，但不幸的是，Paul Graham的写作速度比较慢。如果我们可以根据需要生成创业智慧的样本，岂不美哉？这时就轮到RNN出场了。</p>

<p>合并Paul Graham过去5年的所有文章，我们可以得到大约1MB的文本文件，或者说大约100万个字符（顺便提一句，这是个非常小的数据集）。<em>技术：</em>训练一个2层的LSTM，含有512个隐藏节点（约350万个参数），每层之后有0.5的dropout。我们将通过每批次100个实例和长度为100个字符的截断式沿时间反向传播来训练。使用这些设置，每个批次在TITAN Z GPU上耗时大约0.46秒（这可以通过性能代价微不足道的50个字符的BPTT，即Backpropagation Through Time让耗时减半）。言归正传，让我们看看来自RNN的样本：</p>

<blockquote>
<p>The surprised in investors weren’t going to raise money. I’m not the company with the time there are all interesting quickly, don’t have to get off the same programmers. There’s a super-angel round fundraising, why do you can do. If you have a different physical investment are become in people who reduced in a startup with the way to argument the acquirer could see them just that you’re also the founders will part of users’ affords that and an alternation to the idea. [2] Don’t work at first member to see the way kids will seem in advance of a bad successful startup. And if you have to act the big company too.</p>
</blockquote>

<p>好吧，显然上面的样本暂时还无法取代Paul Graham，但是别忘了，RNN必须使用一个小的数据集（包括逗号，撇号和空格）完全从零开始学习英语。我也很喜欢它学会通过引用来支持自己的论点（例如上面的[2]）。有时候它会说一些有洞见的话，比如“a company is a meeting to think to investors”。如果你想看到更多，<a href="http://cs.stanford.edu/people/karpathy/char-rnn/pg.txt">这里</a>有5万个字符的样本。</p>

<p>温度。我们还可以在取样的时候调节Softmax的温度。将温度从1降至更低的数值（例如0.5）可以让RNN有更高的置信度，但其样本也会更保守。相反地，较高的温度将会带来更多的多样性，但是会以更多的错误为代价（例如拼写错误等）。特别是，将温度设置得非常接近于0时就会得到与Paul Graham更相似的言论：</p>

<blockquote>
<p>is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same</p>
</blockquote>

<p>看起来我们已经陷入了创业的死循环。</p>

<h4 id="莎士比亚">莎士比亚</h4>

<p>看起来RNN可以学习拼写英文单词。但是如果数据中有更多的结构和风格呢？为检验这一点，我下载了莎士比亚的所有作品，并将它们合并成单个（4.4MB）文件。现在我们可以训练一个更大的网络，在这个案例中，我们将尝试一个3层的RNN，每层有512个隐藏节点。在训练网络几个小时之后，我们得到如下的样本：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">PANDARUS:
Alas, I think he shall be come approached and the day
When little srain would be attain&#39;d into being never fed,
And who is but a chain and subjects of his death,
I should not sleep.

Second Senator:
They are away this miseries, produced upon my soul,
Breaking and strongly should be buried, when I perish
The earth and thoughts of many states.

DUKE VINCENTIO:
Well, your wit is in the care of side and that.

Second Lord:
They would be ruled after this chamber, and
my fair nues begun out of the fact, to be conveyed,
Whose noble souls I&#39;ll have the heart of the wars.

Clown:
Come, sir, I will make did behold your worship.

VIOLA:
I&#39;ll drink it.
</code></pre></div>
<p>记住，RNN只知道字符，所以它会对发言者的名字和内容进行取样。有时候我们也会得到相对延伸的独白短文，比如：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">VIOLA:
Why, Salisbury must find his flesh and thought
That which I am not aps, not a man and in fire,
To show the reining of the raven and the wars
To grace my hand reproach within, and not a fair are hand,
That Caesar and my goodly father&#39;s world;
When I was heaven of presence and our fleets,
We spare with hours, but cut thy council I am great,
Murdered and by thy master&#39;s ready there
My power to give thee but so much as hell:
Some service in the noble bondman here,
Would show him to her wine.

KING LEAR:
O, if you were a feeble sight, the courtesy of your law,
Your sight and several breath, will wear the gods
With his heads, and my hands are wonder&#39;d at the deeds,
So drop upon your lordship&#39;s head, and your opinion
Shall be against your honour.
</code></pre></div>
<p>我几乎不能把这些样本从莎士比亚的原作中辨别出来:)如果你喜欢莎士比亚，你可能会喜欢这<a href="http://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt">10万个字符的样本</a>。当然，你也可以使用我提供的代码在不同温度下生成无限数量的你自己的样本。</p>

<h4 id="维基百科">维基百科</h4>

<p>我们看到，LSTM可以学习拼写单词和复制一般的句法结构。让我们进一步增加难度，在结构化的markdown上面训练它。具体地说，就是使用<a href="http://prize.hutter1.net/">Hutter Prize</a> 的维基百科原始数据集（100MB）训练一个LSTM。和<a href="http://arxiv.org/abs/1308.0850">Graves et al.</a>一样，我使用前面的96MB来训练，剩下的用于验证以及在晚上跑几个模型。我们现在可以对维基百科的文章进行取样！以下是一些有趣的摘录：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Naturalism and decision for the majority of Arab countries&#39; capitalide was grounded
by the Irish language by [[John Clair]], [[An Imperial Japanese Revolt]], associated
with Guangzham&#39;s sovereignty. His generals were the powerful ruler of the Portugal
in the [[Protestant Immineners]], which could be said to be directly in Cantonese
Communication, which followed a ceremony and set inspired prison, training. The
emperor travelled back to [[Antioch, Perth, October 25|21]] to note, the Kingdom
of Costa Rica, unsuccessful fashioned the [[Thrales]], [[Cynth&#39;s Dajoard]], known
in western [[Scotland]], near Italy to the conquest of India with the conflict.
Copyright was the succession of independence in the slop of Syrian influence that
was a famous German movement based on a more popular servicious, non-doctrinal
and sexual power post. Many governments recognize the military housing of the
[[Civil Liberalization and Infantry Resolution 265 National Party in Hungary]],
that is sympathetic to be to the [[Punjab Resolution]]
(PJS)[http://www.humah.yahoo.com/guardian.
cfm/7754800786d17551963s89.htm Official economics Adjoint for the Nazism, Montgomery
was swear to advance to the resources for those Socialism&#39;s rule,
was starting to signing a major tripad of aid exile.]]
</code></pre></div>
<p>你可能会注意到，上面的雅虎网址实际上并不存在，是模型生造出来的。另外，还要注意到模型学会了正确地打开和关闭括号。模型学会的结构化markdown还有很多，比如有时候它会创建标题，列表等：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{ { cite journal | id=Cerling Nonforest Department|format=Newlymeslated|none } }
&#39;&#39;www.e-complete&#39;&#39;.

&#39;&#39;&#39;See also&#39;&#39;&#39;: [[List of ethical consent processing]]

== See also ==
*[[Iender dome of the ED]]
*[[Anti-autism]]

===[[Religion|Religion]]===
*[[French Writings]]
*[[Maria]]
*[[Revelation]]
*[[Mount Agamul]]

== External links==
* [http://www.biblegateway.nih.gov/entrepre/ Website of the World Festival. The labour of India-county defeats at the Ripper of California Road.]

==External links==
* [http://www.romanology.com/ Constitution of the Netherlands and Hispanic Competition for Bilabial and Commonwealth Industry (Republican Constitution of the Extent of the Netherlands)]
</code></pre></div>
<p>有时候，模型会生成随机但是有效的XML文件：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&lt;page&gt;
  &lt;title&gt;Antichrist&lt;/title&gt;
  &lt;id&gt;865&lt;/id&gt;
  &lt;revision&gt;
    &lt;id&gt;15900676&lt;/id&gt;
    &lt;timestamp&gt;2002-08-03T18:14:12Z&lt;/timestamp&gt;
    &lt;contributor&gt;
      &lt;username&gt;Paris&lt;/username&gt;
      &lt;id&gt;23&lt;/id&gt;
    &lt;/contributor&gt;
    &lt;minor /&gt;
    &lt;comment&gt;Automated conversion&lt;/comment&gt;
    &lt;text xml:space=&quot;preserve&quot;&gt;#REDIRECT [[Christianity]]&lt;/text&gt;
  &lt;/revision&gt;
&lt;/page&gt;
</code></pre></div>
<p>模型生成timestamp，id等等。另外，还要注意到它会以正确的嵌套顺序恰当地关闭相应的标签。如果你有兴趣看到更多，这里有<a href="http://cs.stanford.edu/people/karpathy/char-rnn/wiki.txt">10万个字符的维基百科样本</a>。</p>

<h4 id="代数几何（latex）">代数几何（Latex）</h4>

<p>以上结果表明，该模型在学习复杂句法结构方面确实相当擅长。这些结果令人印象深刻，我和我的实验室同事（<a href="http://cs.stanford.edu/people/jcjohns/">Justin Johnson</a>）决定在结构化的领域进一步推进。我们找到关于代数叠/几何的<a href="http://stacks.math.columbia.edu/">这本书</a>，下载它的原始Latex源文件（16MB），然后训练一个多层的LSTM。令人惊讶的是，产生的Latex样本几乎是可以编译的。在我们手动修复一些问题后，就得到了看起来似乎合理的数学推论，这是相当惊人的：</p>

<p><img src="/uploads/latex4.jpg" alt="latex4"></p>

<p><em>代数几何样本（假的），<a href="http://cs.stanford.edu/people/jcjohns/fake-math/4.pdf">这里是真正的PDF文件</a>。</em></p>

<p>这是另一份样本：</p>

<p><img src="/uploads/latex3.jpg" alt="latex3"></p>

<p><em>更像代数几何了，还出现了图表（右）。</em></p>

<p>正如你在上面看到的，有时候这个模型试图生成Latex图表，但显然它并不明白图表的具体意思。我也很喜欢它跳过证明的部分（左上角的“Proof omitted”）。当然，Latex有着相对困难的结构化语法格式，甚至我自己都没有完全掌握。例如，这里是一份来自模型的原始样本（未编辑）：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">\begin{proof}
We may assume that $\mathcal{I}$ is an abelian sheaf on $\mathcal{C}$.
\item Given a morphism $\Delta : \mathcal{F} \to \mathcal{I}$
is an injective and let $\mathfrak q$ be an abelian sheaf on $X$.
Let $\mathcal{F}$ be a fibered complex. Let $\mathcal{F}$ be a category.
\begin{enumerate}
\item \hyperref[setain-construction-phantom]{Lemma}
\label{lemma-characterize-quasi-finite}
Let $\mathcal{F}$ be an abelian quasi-coherent sheaf on $\mathcal{C}$.
Let $\mathcal{F}$ be a coherent $\mathcal{O}_X$-module. Then
$\mathcal{F}$ is an abelian catenary over $\mathcal{C}$.
\item The following are equivalent
\begin{enumerate}
\item $\mathcal{F}$ is an $\mathcal{O}_X$-module.
\end{lemma}
</code></pre></div>
<p>这份来自相对像样的模型的样本展示了一些常见的错误。例如，模型打开一个\begin{proof}环境，但却以\end{lemma}结束。我们必须手动修复这种问题，它可能是由于依赖关系太长期的缘故：当模型完成proof时，它已经忘记是在做proof还是lemma。同样地，它打开一个\begin{enumerate}，但却忘记关闭它。我们观察到，在使用更大/更好的模型时，这些问题会变少，但尽管如此，这些问题还是会出现。</p>

<h4 id="linux源代码">Linux源代码</h4>

<p>我想把结构化的数据推到极限，所以最后的挑战是我决定使用代码。首先，我从<a href="https://github.com/torvalds/linux">GitHub上的Linux库</a>中提取所有的源文件和头文件，将它们合并成单个巨大的文件（474MB的C代码）（我本来只打算在内核上训练，但是其大小只有约16MB）。然后，我花几天的时间训练出几个大小刚好适合我的GPU的3层LSTM网络。这些模型有大约1000万个参数，对于RNN模型来说仍然很少。结果超级有趣：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">/*
 * Increment the size file of the new incorrect UI_FILTER group information
 * of the size generatively.
 */
static int indicate_policy(void)
{
  int error;
  if (fd == MARN_EPT) {
    /*
     * The kernel blank will coeld it to userspace.
     */
    if (ss-&gt;segment &lt; mem_total)
      unblock_graph_and_set_blocked();
    else
      ret = 1;
    goto bail;
  }
  segaddr = in_SB(in.addr);
  selector = seg / 16;
  setup_works = true;
  for (i = 0; i &lt; blocks; i++) {
    seq = buf[i++];
    bpf = bd-&gt;bd.next + i * search;
    if (fd) {
      current = blocked;
    }
  }
  rw-&gt;name = &quot;Getjbbregs&quot;;
  bprm_self_clearl(&amp;iv-&gt;version);
  regs-&gt;new = blocks[(BPF_STATS &lt;&lt; info-&gt;historidac)] | PFMR_CLOBATHINC_SECONDS &lt;&lt; 12;
  return segtable;
}
</code></pre></div>
<p>这些代码整体上看起来非常棒。当然，这些代码是不能够编译的，但是当你滚动这些生成的代码的时候，它给你的感觉非常像是一个巨大的C代码库。注意，RNN会随机地生成带有注释的代码。它很少会犯语法错误。比如，它能正确地使用字符串、指针表示法等。它也能正确地打开和关闭括号{[，学会很好地缩进代码。一个常见的错误是它不能跟踪变量：它经常使用未定义的变量（例如上面的rw），声明从不使用的变量（例如int error），或者返回不存在的变量。让我们看看更多的示例。这是另外一段代码，显示RNN学到的更多操作：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">/*
 * If this error is set, we will need anything right after that BSD.
 */
static void action_new_function(struct s_stat_info *wb)
{
  unsigned long flags;
  int lel_idx_bit = e-&gt;edd, *sys &amp; ~((unsigned long) *FIRST_COMPAT);
  buf[0] = 0xFFFFFFFF &amp; (bit &lt;&lt; 4);
  min(inc, slist-&gt;bytes);
  printk(KERN_WARNING &quot;Memory allocated %02x/%02x, &quot;
    &quot;original MLL instead\n&quot;),
    min(min(multi_run - s-&gt;len, max) * num_data_in),
    frame_pos, sz + first_seg);
  div_u64_w(val, inb_p);
  spin_unlock(&amp;disk-&gt;queue_lock);
  mutex_unlock(&amp;s-&gt;sock-&gt;mutex);
  mutex_unlock(&amp;func-&gt;mutex);
  return disassemble(info-&gt;pending_bh);
}

static void num_serial_settings(struct tty_struct *tty)
{
  if (tty == tty)
    disable_single_st_p(dev);
  pci_disable_spool(port);
  return 0;
}

static void do_command(struct seq_file *m, void *v)
{
  int column = 32 &lt;&lt; (cmd[2] &amp; 0x80);
  if (state)
    cmd = (int)(int_state ^ (in_8(&amp;ch-&gt;ch_flags) &amp; Cmd) ? 2 : 1);
  else
    seq = 1;
  for (i = 0; i &lt; 16; i++) {
    if (k &amp; (1 &lt;&lt; 1))
      pipe = (in_use &amp; UMXTHREAD_UNCCA) +
        ((count &amp; 0x00000000fffffff8) &amp; 0x000000f) &lt;&lt; 8;
    if (count == 0)
      sub(pid, ppc_md.kexec_handle, 0x20000000);
    pipe_set_bytes(i, 0);
  }
  /* Free our user pages pointer to place camera if all dash */
  subsystem_info = &amp;of_changes[PAGE_SIZE];
  rek_controls(offset, idx, &amp;soffset);
  /* Now we want to deliberately put it to device */
  control_check_polarity(&amp;context, val, 0);
  for (i = 0; i &lt; COUNTER; i++)
    seq_puts(s, &quot;policy &quot;);
}
</code></pre></div>
<p>注意，在第二个函数中，模型会比较tty == tty，这永远为真。另一方面，至少变量tty这次在函数范围内存在！在最后一个函数中，代码没有返回任何值，这是正确的，因为函数签名是void。但是，前面两个函数同样声明为void，确有返回值。这又是由于长期相互作用导致的常见错误。</p>

<p>有时候模型会决定是时候对新文件进行取样。这通常是非常有趣的部分：模型首先一个字符一个字符地复述GNU许可证，包含几个头文件，声明一些宏，然后就开始生成代码部分：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">/*
 *  Copyright (c) 2006-2010, Intel Mobile Communications.  All rights reserved.
 *
 *   This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 as published by
 * the Free Software Foundation.
 *
 *        This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *
 *  GNU General Public License for more details.
 *
 *   You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software Foundation,
 *  Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

#include &lt;linux/kexec.h&gt;
#include &lt;linux/errno.h&gt;
#include &lt;linux/io.h&gt;
#include &lt;linux/platform_device.h&gt;
#include &lt;linux/multi.h&gt;
#include &lt;linux/ckevent.h&gt;

#include &lt;asm/io.h&gt;
#include &lt;asm/prom.h&gt;
#include &lt;asm/e820.h&gt;
#include &lt;asm/system_info.h&gt;
#include &lt;asm/setew.h&gt;
#include &lt;asm/pgproto.h&gt;

#define REG_PG    vesa_slot_addr_pack
#define PFM_NOCOMP  AFSR(0, load)
#define STACK_DDR(type)     (func)

#define SWAP_ALLOCATE(nr)     (e)
#define emulate_sigs()  arch_get_unaligned_child()
#define access_rw(TST)  asm volatile(&quot;movd %%esp, %0, %3&quot; : : &quot;r&quot; (0));   \
  if (__type &amp; DO_READ)

static void stat_PC_SEC __read_mostly offsetof(struct seq_argsqueue, \
          pC&gt;[1]);

static void
os_prefix(unsigned long sys)
{
#ifdef CONFIG_PREEMPT
  PUT_PARAM_RAID(2, sel) = get_state_state();
  set_pid_sum((unsigned long)state, current_state_str(),
           (unsigned long)-1-&gt;lr_full; low;
}
</code></pre></div>
<p>这里面有太多有趣的地方需要涉及——仅仅这部分我大概就能写一整篇博文。现在我就不再多说，这里有<a href="http://cs.stanford.edu/people/karpathy/char-rnn/linux.txt">1MB的Linux代码样本</a>供你欣赏。</p>

<h4 id="生成婴儿名字">生成婴儿名字</h4>

<p>让我们尝试一个更好玩的。给RNN提供一个包含8000个婴儿名字的文本文件，每个名字一行（名字从<a href="http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/">这里</a>获得）。 我们可以把这些名字喂给RNN，然后生成新的名字！以下是一些示例名字，只显示训练数据中没有出现的（90%不会）：</p>

<p><em>Rudi Levette Berice Lussa Hany Mareanne Chrestina Carissy Marylen Hammine Janye Marlise Jacacrie Hendred Romand Charienna Nenotto Ette Dorane Wallen Marly Darine Salina Elvyn Ersia Maralena Minoria Ellia Charmin Antley Nerille Chelon Walmor Evena Jeryly Stachon Charisa Allisa Anatha Cathanie Geetra Alexie Jerin Cassen Herbett Cossie Velen Daurenge Robester Shermond Terisa Licia Roselen Ferine Jayn Lusine Charyanne Sales Sanny Resa Wallon Martine Merus Jelen Candica Wallin Tel Rachene Tarine Ozila Ketia Shanne Arnande Karella Roselina Alessia Chasty Deland Berther Geamar Jackein Mellisand Sagdy Nenc Lessie Rasemy Guen Gavi Milea Anneda Margoris Janin Rodelin Zeanna Elyne Janah Ferzina Susta Pey Castina</em></p>

<p>你可以在<a href="http://cs.stanford.edu/people/karpathy/namesGenUnique.txt">这里</a>看到更多。我最喜欢的名字包括“Baby”（哈哈）、“Killie”、“Char”、“R”、“More”、“Mars”、“Hi”、“Saddie”、“With”和“Ahbort”。这确实很有意思。当然，你还可以在写小说、命名或者给创业公司起名字的时候把它当作相当有用的灵感来源:)</p>

<h3 id="理解到底发生了什么">理解到底发生了什么</h3>

<p>我们看到，在训练结束时的结果令人印象深刻，但是这些工作是如何进行的呢？让我们跑两个快速的实验来简单地窥视一下。</p>

<h4 id="训练中样本的演变">训练中样本的演变</h4>

<p>首先，看看样本文本在模型训练的过程中是如何演变的。例如，我用列夫·托尔斯泰的《战争与和平》来训练LSTM，然后每100次训练就产生一次样本。在第100次迭代时，模型取样的文本是随机杂凑的：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">tyntd-iafhatawiaoihrdemot  lytdws  e ,tfti, astai f ogoh eoase rrranbyne &#39;nhthnee e
plia tklrgd t o idoe ns,smtt   h ne etie h,hregtrs nigtike,aoaenns lng
</code></pre></div>
<p>但是请注意，至少它开始意识到单词要用空格分开。有时候它偶尔会插入两个空格。它也不知道逗号后面几乎总是有个空格。在迭代300次后，我们看到模型开始学会使用引号和句号：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;Tmont thithey&quot; fomesscerliund
Keushey. Thom here
sheulke, anmerenith ol sivh I lalterthend Bleipile shuwy fil on aseterlome
coaniogennc Phe lism thond hon at. MeiDimorotion in ther thize.&quot;
</code></pre></div>
<p>这些单词同样被空格分开，模型开始在句子结尾处使用句号。在第500次迭代时：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">we counter. He stutn co des. His stanted out one ofler that concossions and was
to gearang reay Jotrets and with fre colt otf paitt thin wall. Which das stimn
</code></pre></div>
<p>模式已经学会拼写最短和最常见的单词，如“we”、“He”、“His”、“Which”、“and”等。在第700次迭代时，我们开始看到越来越像英语的文本出现：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Aftair fall unsuch that the hall for Prince Velzonski&#39;s that me of
her hearly, and behs to so arwage fiving were to it beloge, pavu say falling misfort
how, and Gogition is so overelical and ofter.
</code></pre></div>
<p>在第1200次迭代时，我们看到引号、问号和感叹号的使用。同时还出现了更长的单词：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;Kite vouch!&quot; he repeated by her
door. &quot;But I would be done and quarts, feeling, then, son is people....&quot;
</code></pre></div>
<p>直到大约第2000次迭代时，我们才开始得到正确拼写的单词、引述、名字等等：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;Why do what that day,&quot; replied Natasha, and wishing to himself the fact the
princess, Princess Mary was easier, fed in had oftened him.
Pierre aking his soul came to the packs and drove up his father-in-law women.
</code></pre></div>
<p>从上述描述中可知，模型首先是发现单词-空格这样普遍的结构，然后迅速开始学习单词：首先从简短的单词开始，然后是更长的单词。跨越多个单词的话题和主题（以及一般的长期依赖关系）要到很久以后才会出现。</p>

<h4 id="可视化rnn中的预测与神经元激活">可视化RNN中的预测与神经元激活</h4>

<p>Another fun visualization is to look at the predicted distributions over characters. In the visualizations below we feed a Wikipedia RNN model character data from the validation set (shown along the blue/green rows) and under every character we visualize (in red) the top 5 guesses that the model assigns for the next character. The guesses are colored by their probability (so dark red = judged as very likely, white = not very likely). For example, notice that there are stretches of characters where the model is extremely confident about the next letter (e.g., the model is very confident about characters during the <a href="http://www">http://www</a>. sequence).</p>

<p>另一个有趣的可视化是看看字符的预测分布。在下面的可视化中，我们把验证集（显示在蓝色/绿色的行中）中字符数据提供给维基百科RNN模型，在每个字符下面我们可视化（红色）模型为下一个字符分配前5个猜测。猜测是根据它们的概率着色的（所以暗红色被认为是非常可能的，白色=不太可能）。例如，请注意，模型对下一个字母非常有信心（例如，在http：// www。序列期间，模型对字符非常有信心）中有一定范围的字符。</p>

<p>输入字符序列（蓝/绿）是基于在RNN的隐藏表示中随机选择的神经元的发射而着色的。想想看，绿色=非常激动，蓝色=不太兴奋（对于那些熟悉LSTM细节的人来说，隐藏状态向量中的值为[-1,1]之间，这就是门控和双稳态LSTM单元州）。直观地说，这是在读取输入序列的同时，将RNN的“大脑”中的一些神经元的放电率可视化。不同的神经元可能在寻找不同的模式;下面我们来看看我发现并认为是有趣或可解释的4个不同的（很多也不是）：
The input character sequence (blue/green) is colored based on the firing of a randomly chosen neuron in the hidden representation of the RNN. Think about it as green = very excited and blue = not very excited (for those familiar with details of LSTMs, these are values between [-1,1] in the hidden state vector, which is just the gated and tanh’d LSTM cell state). Intuitively, this is visualizing the firing rate of some neuron in the “brain” of the RNN while it reads the input sequence. Different neurons might be looking for different patterns; Below we’ll look at 4 different ones that I found and thought were interesting or interpretable (many also aren’t):</p>

<p><img src="/uploads/under1.jpg" alt="under1"></p>

<p>The neuron highlighted in this image seems to get very excited about URLs and turns off outside of the URLs. The LSTM is likely using this neuron to remember if it is inside a URL or not.
<em>在这个图像中突出显示的神经元似乎对URL感到非常兴奋，并在URL之外关闭。 LSTM很可能使用这个神经元来记住它是否在URL内部。</em></p>

<p><img src="/uploads/under2.jpg" alt="under2"></p>

<p>The highlighted neuron here gets very excited when the RNN is inside the [[ ]] markdown environment and turns off outside of it. Interestingly, the neuron can&#39;t turn on right after it sees the character &quot;[&quot;, it must wait for the second &quot;[&quot; and then activate. This task of counting whether the model has seen one or two &quot;[&quot; is likely done with a different neuron.
<em>当RNN在[[]]降价环境内时，突出显示的神经元在此处变得非常兴奋，并在其外部关闭。 有趣的是，神经元在看到字符“[”后不能右转，它必须等待第二个“[”然后激活。 计算模型是否已经看到一个或两个“[”的任务可能是用不同的神经元完成的。</em></p>

<p><img src="/uploads/under3.jpg" alt="under3"></p>

<p>Here we see a neuron that varies seemingly linearly across the [[ ]] environment. In other words its activation is giving the RNN a time-aligned coordinate system across the [[ ]] scope. The RNN can use this information to make different characters more or less likely depending on how early/late it is in the [[ ]] scope (perhaps?).
在这里，我们看到一个神经元在整个[[]]环境中看似线性地变化。 换句话说，它的激活给RNN提供了一个跨越[[]]范围的时间对齐的坐标系统。 RNN可以使用这些信息来制作不同的角色，这取决于[[]]范围（也许是？）的早/晚。</p>

<p><img src="/uploads/under4.jpg" alt="under4"></p>

<p>Here is another neuron that has very local behavior: it is relatively silent but sharply turns off right after the first &quot;w&quot; in the &quot;www&quot; sequence. The RNN might be using this neuron to count up how far in the &quot;www&quot; sequence it is, so that it can know whether it should emit another &quot;w&quot;, or if it should start the URL.
<em>这里是另一个具有非常本地行为的神经元：它是相对沉默的，但在“www”序列中的第一个“w”之后立即关闭。 RNN可能使用这个神经元来计算它在“www”序列中有多远，以便它可以知道是否应该发出另一个“w”，或者是否应该启动URL。</em></p>

<p>Of course, a lot of these conclusions are slightly hand-wavy as the hidden state of the RNN is a huge, high-dimensional and largely distributed representation. These visualizations were produced with custom HTML/CSS/Javascript, you can see a sketch of what’s involved here if you’d like to create something similar.
当然，由于RNN的隐藏状态是一个巨大的，高维度的，在很大程度上是分布式的表示，所以这些结论有些是手摇的。 这些可视化是用自定义的HTML / CSS / Javascript生成的，如果你想创建类似的东西，你可以看到这里包含的内容。</p>

<p>我们也可以通过排除最可能的预测来压缩这个可视化，并且仅仅通过单元的激活来显现文本。 我们可以看到，除了大部分没有做任何解释的单元之外，其中大约5％的单元学会了相当有趣和可解释的算法：
We can also condense this visualization by excluding the most likely predictions and only visualize the text, colored by activations of a cell. We can see that in addition to a large portion of cells that do not do anything interpretible, about 5% of them turn out to have learned quite interesting and interpretible algorithms:</p>

<p><img src="/uploads/pane1.png" alt="pane1">
<img src="/uploads/pane2.png" alt="pane2"></p>

<p>Again, what is beautiful about this is that we didn’t have to hardcode at any point that if you’re trying to predict the next character it might, for example, be useful to keep track of whether or not you are currently inside or outside of quote. We just trained the LSTM on raw data and it decided that this is a useful quantitity to keep track of. In other words one of its cells gradually tuned itself during training to become a quote detection cell, since this helps it better perform the final task. This is one of the cleanest and most compelling examples of where the power in Deep Learning models (and more generally end-to-end training) is coming from.
再一次，美丽的是，我们不必硬编码，如果你想预测下一个字符，它可能会有助于跟踪你是否目前在或 报价之外。 我们刚刚对原始数据进行了LSTM训练，并决定这是一个有用的数量来跟踪。 换句话说，其中一个细胞在训练过程中逐渐调整成报价检测单元，因为这有助于更好地完成最终的任务。 这是深度学习模型（更普遍的端到端培训）的力量来自哪里的最干净和最引人注目的例子之一。</p>

<h3 id="源代码">源代码</h3>

<p>I hope I’ve convinced you that training character-level language models is a very fun exercise. You can train your own models using the char-rnn code I released on Github (under MIT license). It takes one large text file and trains a character-level model that you can then sample from. Also, it helps if you have a GPU or otherwise training on CPU will be about a factor of 10x slower. In any case, if you end up training on some data and getting fun results let me know! And if you get lost in the Torch/Lua codebase remember that all it is is just a more fancy version of this 100-line gist.
我希望我已经说服你，训练人物级别的语言模型是一个非常有趣的练习。您可以使用我在Github上发布的char-rnn代码（在MIT许可证下）来训练自己的模型。它需要一个大的文本文件，并训练一个字符级模型，然后你可以从中进行抽样。此外，如果你有一个GPU或其他CPU的培训，这将有助于慢10倍。无论如何，如果您最终对某些数据进行培训并获得乐趣，请告诉我！如果你迷失在火炬/ Lua代码库中，请记住，它只是这个100行要点的更加花哨的版本。</p>

<p>简短的离题。代码是用Torch 7编写的，最近我成了我最喜欢的深度学习框架。我在过去的几个月里才开始使用Torch / LUA，这并不容易（我花了很多时间在Github上查看原始的Torch代码，并且询问他们的问题以完成工作），但是一旦你得到了一堆东西，它提供了很大的灵活性和速度。我以前也和Caffe和Theano一起工作过，我认为火炬虽然不完美，但是比其他人的抽象和哲学水平要好。在我看来，有效框架的理想特征是：
Brief digression. The code is written in Torch 7, which has recently become my favorite deep learning framework. I’ve only started working with Torch/LUA over the last few months and it hasn’t been easy (I spent a good amount of time digging through the raw Torch code on Github and asking questions on their gitter to get things done), but once you get a hang of things it offers a lot of flexibility and speed. I’ve also worked with Caffe and Theano in the past and I believe Torch, while not perfect, gets its levels of abstraction and philosophy right better than others. In my view the desirable features of an effective framework are:</p>

<p>CPU/GPU transparent Tensor library with a lot of functionality (slicing, array/matrix operations, etc. )
    An entirely separate code base in a scripting language (ideally Python) that operates over Tensors and implements all Deep Learning stuff (forward/backward, computation graphs, etc)
    It should be possible to easily share pretrained models (Caffe does this well, others don’t), and crucially
    NO compilation step (or at least not as currently done in Theano). The trend in Deep Learning is towards larger, more complex networks that are are time-unrolled in complex graphs. It is critical that these do not compile for a long time or development time greatly suffers. Second, by compiling one gives up interpretability and the ability to log/debug effectively. If there is an option to compile the graph once it has been developed for efficiency in prod that’s fine.
1. 具有许多功能的CPU / GPU透明张量库（切片，阵列/矩阵操作等）
2. 一个完全独立的脚本语言（理想的是Python）的代码库，通过张量运行并实现所有深度学习的东西（向前/向后，计算图等）
3. 应该可以轻松地分享预训练的模型（Caffe做的很好，其他人不这样做）
4. 关键的是没有编译步骤（或者至少不是目前在Theano中完成的）。深度学习的趋势是朝着更复杂，更复杂的网络进行时间展开。这些不长时间编译或者开发时间受到严重影响是非常重要的。 其次，通过编写一个放弃解释性和有效记录/调试的能力。 如果有一个选项可以编译图表，一旦它已经被开发出来，效率很高。</p>

<h3 id="进一步阅读">进一步阅读</h3>

<p>Before the end of the post I also wanted to position RNNs in a wider context and provide a sketch of the current research directions. RNNs have recently generated a significant amount of buzz and excitement in the field of Deep Learning. Similar to Convolutional Networks they have been around for decades but their full potential has only recently started to get widely recognized, in large part due to our growing computational resources. Here’s a brief sketch of a few recent developments (definitely not complete list, and a lot of this work draws from research back to 1990s, see related work sections):
在这篇文章结束之前，我也想把RNN放在更广泛的背景下，并提供当前研究方向的简图。 RNN最近在深度学习领域引起了大量的热议和兴奋。 与卷积网络类似，它们已经存在了几十年，但是它们的全部潜力最近才开始得到广泛的认可，这在很大程度上是由于我们不断增长的计算资源。 下面简要地介绍一些最近的发展情况（绝对不是完整的清单，这项工作很多都是从20世纪90年代的研究中吸取的，参见相关的工作部分）：</p>

<p>In the domain of NLP/Speech, RNNs transcribe speech to text, perform machine translation, generate handwritten text, and of course, they have been used as powerful language models (Sutskever et al.) (Graves) (Mikolov et al.) (both on the level of characters and words). Currently it seems that word-level models work better than character-level models, but this is surely a temporary thing.
在NLP / Speech领域，RNN将语音转换为文本，执行机器翻译，生成手写文本，当然，它们也被用作强大的语言模型（Sutskever等人）（Graves）（Mikolov等人）（ 既在字符和文字层面）。 目前看来，字级模型比字符级模型更好，但这肯定是暂时的。</p>

<p>Computer Vision. RNNs are also quickly becoming pervasive in Computer Vision. For example, we’re seeing RNNs in frame-level video classification, image captioning (also including my own work and many others), video captioning and very recently visual question answering. My personal favorite RNNs in Computer Vision paper is Recurrent Models of Visual Attention, both due to its high-level direction (sequential processing of images with glances) and the low-level modeling (REINFORCE learning rule that is a special case of policy gradient methods in Reinforcement Learning, which allows one to train models that perform non-differentiable computation (taking glances around the image in this case)). I’m confident that this type of hybrid model that consists of a blend of CNN for raw perception coupled with an RNN glance policy on top will become pervasive in perception, especially for more complex tasks that go beyond classifying some objects in plain view.
计算机视觉。 RNN在计算机视觉中也迅速普及。例如，我们看到了帧级视频分类，图像字幕（还包括我自己的工作以及其他许多内容），视频字幕以及最近的视觉问题回答。在计算机视觉论文中，我个人最喜欢的RNN是视觉注意的递归模型，这是由于其高层次的方向（图像的顺序处理）和低层建模（增强学习规则，这是策略梯度方法的一个特例在强化学习中，它允许训练执行非微分计算的模型（在这种情况下对图像进行扫视）。我相信，这种类型的混合模型，包括原始感知的CNN和RNN瞥视策略的混合，将在感知中变得无处不在，特别是对于更复杂的任务，它们不仅仅是在一般视图中对某些对象进行分类。</p>

<p>归纳推理，回忆与注意。另一个极其令人兴奋的研究方向是解决香草经常性网络的局限性。一个问题是RNNs不是归纳性的：它们很好地记忆序列，但是它们不一定总是以正确的方式显示令人信服的泛化符号（我会稍微提供一些指示，使其更加具体）。第二个问题是他们不必要地将表示大小与每步的计算量相结合。例如，如果将隐藏状态矢量的大小加倍，则由于矩阵乘法的原因，每一步的FLOPS数量会增加四倍。理想情况下，我们希望保持一个巨大的表示/内存（例如包含所有维基百科或许多中间状态变量），同时保持每个时间步长固定的计算能力。
Inductive Reasoning, Memories and Attention. Another extremely exciting direction of research is oriented towards addressing the limitations of vanilla recurrent networks. One problem is that RNNs are not inductive: They memorize sequences extremely well, but they don’t necessarily always show convincing signs of generalizing in the correct way (I’ll provide pointers in a bit that make this more concrete). A second issue is they unnecessarily couple their representation size to the amount of computation per step. For instance, if you double the size of the hidden state vector you’d quadruple the amount of FLOPS at each step due to the matrix multiplication. Ideally, we’d like to maintain a huge representation/memory (e.g. containing all of Wikipedia or many intermediate state variables), while maintaining the ability to keep computation per time step fixed.</p>

<p>The first convincing example of moving towards these directions was developed in DeepMind’s Neural Turing Machines paper. This paper sketched a path towards models that can perform read/write operations between large, external memory arrays and a smaller set of memory registers (think of these as our working memory) where the computation happens. Crucially, the NTM paper also featured very interesting memory addressing mechanisms that were implemented with a (soft, and fully-differentiable) attention model. The concept of soft attention has turned out to be a powerful modeling feature and was also featured in Neural Machine Translation by Jointly Learning to Align and Translate for Machine Translation and Memory Networks for (toy) Question Answering. In fact, I’d go as far as to say that
在DeepMind的Neural Turing Machines论文中，第一个令人信服的朝着这些方向发展的例子被开发出来了。 本文勾勒出一个模型的路径，该模型可以在计算发生的大型外部存储器阵列和较小的一组存储器寄存器之间执行读取/写入操作（将它们视为我们的工作存储器）。 至关重要的是，非关税措施报告还特别提出了一个非常有趣的记忆寻址机制，这个机制是用一个（软和完全可微的）关注模型来实现的。 软关注的概念已被证明是一个强大的建模功能，也被用于（玩具）问题回答联合学习对齐和翻译机器翻译和记忆网络的神经机器翻译。 事实上，我甚至可以这么说</p>

<blockquote>
<p>The concept of attention is the most interesting recent architectural innovation in neural networks.</p>
</blockquote>

<p>Now, I don’t want to dive into too many details but a soft attention scheme for memory addressing is convenient because it keeps the model fully-differentiable, but unfortunately one sacrifices efficiency because everything that can be attended to is attended to (but softly). Think of this as declaring a pointer in C that doesn’t point to a specific address but instead defines an entire distribution over all addresses in the entire memory, and dereferencing the pointer returns a weighted sum of the pointed content (that would be an expensive operation!). This has motivated multiple authors to swap soft attention models for hard attention where one samples a particular chunk of memory to attend to (e.g. a read/write action for some memory cell instead of reading/writing from all cells to some degree). This model is significantly more philosophically appealing, scalable and efficient, but unfortunately it is also non-differentiable. This then calls for use of techniques from the Reinforcement Learning literature (e.g. REINFORCE) where people are perfectly used to the concept of non-differentiable interactions. This is very much ongoing work but these hard attention models have been explored, for example, in Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets, Reinforcement Learning Neural Turing Machines, and Show Attend and Tell.
现在，我不想过多细节，但是对于内存寻址的软注意方案是很方便的，因为它使得模型完全可以区分，但是不幸的是牺牲了效率，因为所有可以关注的东西都被注意到了（但是轻轻地）。可以认为这是在C语言中声明一个指向特定地址的指针，而是在整个内存中的所有地址上定义一个完整的分配，并且解除引用指针返回指向内容的加权和（这将是一个昂贵的操作！）。这激发了多个作者交换软注意力模型，以便在对某个特定的存储器块进行采样（例如，对某些存储器单元的读/写动作而不是从某种程度上对所有单元格的读/写）进行采样的情况下进行硬注意。这个模型在哲学上更具吸引力，可扩展性和高效性，但不幸的是它也是不可区分的。这就要求使用来自强化学习文献（例如REINFORCE）的技术，其中人们完全习惯于不可区分的相互作用的概念。这是非常正在进行的工作，但是这些硬注意力模型已经被探索，例如，推导堆栈增强循环网络的算法模式，增强学习神经图灵机，和显示参加和告诉。</p>

<p>人。如果您想阅读RNN，我推荐Alex Graves，Ilya Sutskever和Tomas Mikolov的提纲。有关REINFORCE和更一般的强化学习和政策梯度方法（REINFORCE是David Silver的一个特例，或Pieter Abbeel的一个类）的更多内容。
People. If you’d like to read up on RNNs I recommend theses from Alex Graves, Ilya Sutskever and Tomas Mikolov. For more about REINFORCE and more generally Reinforcement Learning and policy gradient methods (which REINFORCE is a special case of) David Silver’s class, or one of Pieter Abbeel’s classes.</p>

<p>Code. If you’d like to play with training RNNs I hear good things about keras or passage for Theano, the code released with this post for Torch, or this gist for raw numpy code I wrote a while ago that implements an efficient, batched LSTM forward and backward pass. You can also have a look at my numpy-based NeuralTalk which uses an RNN/LSTM to caption images, or maybe this Caffe implementation by Jeff Donahue.
码。 如果你想玩RNN的训练，我会听到关于keano的一些好消息，或者是为Theano发布的这段代码，或者是我刚才写的原始numpy代码的主要代码，这个代码实现了一个高效，批量的LSTM转发 和落后的传球。 你也可以看看我的基于numpy的NeuralTalk，它使用RNN / LSTM来标记图像，或者Jeff Donahue的这个Caffe实现。</p>

<h3 id="总结">总结</h3>

<p>We’ve learned about RNNs, how they work, why they have become a big deal, we’ve trained an RNN character-level language model on several fun datasets, and we’ve seen where RNNs are going. You can confidently expect a large amount of innovation in the space of RNNs, and I believe they will become a pervasive and critical component to intelligent systems.
我们已经了解了RNN，它们是如何工作的，为什么它们已经成为大事，我们已经在几个有趣的数据集上训练了一个RNN字符级的语言模型，并且我们已经看到了RNN的去向。 您可以自信地期待RNN领域的大量创新，我相信它们将成为智能系统的普遍和关键组成部分。</p>

<p>最后，为了给这篇文章增加一些元素，我在这个博客文章的源文件上培训了一个RNN。 不幸的是，在大约46K字符处，我没有写足够的数据来正确输入RNN，但是返回的样本（用低温产生以获得更典型的样本）是：
Lastly, to add some meta to this post, I trained an RNN on the source file of this blog post. Unfortunately, at about 46K characters I haven’t written enough data to properly feed the RNN, but the returned sample (generated with low temperature to get a more typical sample) is:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">I&#39;ve the RNN with and works, but the computed with program of the
RNN with and the computed of the RNN with with and the code
</code></pre></div>
<p>是的，这篇博文讲的是RNN和它的效果如何，很明显它工作良好:)下次再见！</p>

<p>编辑（额外链接）：</p>

<p>视频:</p>

<ul>
<li>I gave a talk on this work at the <a href="https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks">London Deep Learning meetup (video)</a>.</li>
</ul>

<p>讨论:</p>

<ul>
<li><a href="https://news.ycombinator.com/item?id=9584325">HN discussion</a></li>
<li>Reddit discussion on <a href="http://www.reddit.com/r/MachineLearning/comments/36s673/the_unreasonable_effectiveness_of_recurrent/">r/machinelearning</a></li>
<li>Reddit discussion on <a href="http://www.reddit.com/r/programming/comments/36su8d/the_unreasonable_effectiveness_of_recurrent/">r/programming</a></li>
</ul>

<p>回复:</p>

<ul>
<li><a href="https://twitter.com/yoavgo">Yoav Goldberg</a> compared these RNN results to <a href="http://nbviewer.ipython.org/gist/yoavg/d76121dfde2618422139">n-gram maximum likelihood (counting) baseline</a></li>
<li><a href="https://twitter.com/nylk">@nylk</a> trained char-rnn on <a href="https://gist.github.com/nylki/1efbaa36635956d35bcc">cooking recipes</a>. 它们看起来非常棒！</li>
<li><a href="https://twitter.com/MrChrisJohnson">@MrChrisJohnson</a> trained char-rnn on Eminem lyrics and then synthesized a rap song with robotic voice reading it out. Hilarious :)</li>
<li><a href="https://twitter.com/samim">@samim</a> trained char-rnn on <a href="https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0">Obama Speeches</a>. They look fun!</li>
<li><a href="https://twitter.com/seaandsailor">João Felipe</a> trained char-rnn irish folk music and <a href="https://soundcloud.com/seaandsailor/sets/char-rnn-composes-irish-folk-music">sampled music</a></li>
<li><a href="https://twitter.com/boblsturm">Bob Sturm</a> also trained char-rnn on <a href="https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/">music in ABC notation</a></li>
<li><a href="https://twitter.com/RNN_Bible">RNN Bible bot</a> by <a href="https://twitter.com/the__glu/with_replies">Maximilien</a></li>
<li><a href="http://cpury.github.io/learning-holiness/">Learning Holiness</a> learning the Bible</li>
<li><a href="https://www.terminal.com/tiny/ZMcqdkWGOM">Terminal.com snapshot</a> that has char-rnn set up and ready to go in a browser-based virtual machine (thanks <a href="https://www.twitter.com/samim">@samim</a>)</li>
</ul>
]]></content>
  </entry>
  
</feed>
