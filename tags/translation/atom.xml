<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: Translation | 乐者为王]]></title>
  <link href="http://codemany.com/tags/translation/atom.xml" rel="self"/>
  <link href="http://codemany.com/"/>
  <updated>2018-02-27T10:19:35+08:00</updated>
  <id>http://codemany.com/</id>
  <author>
    <name><![CDATA[dohkoos]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[循环神经网络不可思议的效用]]></title>
    <link href="http://codemany.com/blog/rnn-effectiveness/"/>
    <updated>2018-01-07T09:44:50+08:00</updated>
    <id>http://codemany.com/blog/rnn-effectiveness</id>
    <content type="html"><![CDATA[<p>英文原文：<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></p>

<p>循环神经网络（RNN）有些神奇的地方。我仍然记得我为<a href="http://cs.stanford.edu/people/karpathy/deepimagesent/">图像标注</a>而训练我的首个循环网络的情景。我的第一个幼稚模型（带有相当随意选择的超参数）在经过几十分钟的训练后就开始在图像的有意义的边缘产生非常漂亮的描述。有时候，模型的简单与你从中得到的结果的质量之间的比例超过你的预期，这次就是一个例子。为什么当时这个结果如此令人震惊？普遍的看法是，RNN应该是很难训练的（随着更多的实践，我实际上得到了相反的结论）。在这之后的1年：我一直在训练RNN，并多次见证它的能力和健壮性，但它的神奇输出仍然让我感到有趣。这篇文章将与你分享一些RNN的魔法。</p>

<blockquote>
<p>我们将训练RNN让它一个字符一个字符地生成文本，然后思考“这怎么可能？”</p>
</blockquote>

<p>顺便说一句，我会把这篇文章涉及的<a href="https://github.com/karpathy/char-rnn">代码</a>发布到GitHub上，它可以让你基于多层LSTM来训练字符级别的语言模型。你给它输入大量的文本，它将学会生成类似的文本。你也可以用它来复现我下面的实验。那么RNN究竟是什么呢？</p>

<h3 id="循环神经网络">循环神经网络</h3>

<p>序列。Vanilla神经网络（还有卷积网络）最大的局限性在于它的API太受约束：它接受固定大小的向量作为输入（例如图像），然后产生固定大小的向量作为输出（例如不同分类的概率）。不仅如此：这些模型使用固定数量的计算步骤（例如模型中的层数）执行这种映射。循环神经网络如此令人兴奋的主要原因是它允许我们对向量的序列进行操作：输入中的序列、输出中的序列、或者最普遍情况下的输入输出序列。下面是几个具体的示例：</p>

<p><img src="/uploads/diags.jpg" alt="diags"></p>

<p>每个矩形都是一个向量，箭头代表函数（例如矩阵乘法）。输入向量为红色，输出向量为蓝色，绿色向量是RNN的状态。从左到右是：</p>

<ol>
<li>没有RNN的Vanilla处理模式，从固定大小的输入到固定大小的输出（例如图像分类）。</li>
<li>序列输出（例如图像标注，输入图像然后输出一段文字序列）。</li>
<li>序列输入（例如情感分析，给定的文字被分类为表达正面或者负面情感）。</li>
<li>序列输入和序列输出（例如机器翻译：RNN读取英语句子然后以法语的形式输出）。</li>
<li>同步序列输入和输出（例如视频分类，对视频的每个帧打标签）。</li>
</ol>

<p>注意，每个案例都没有对序列长度进行预先规定，因为循环变换（绿色）是固定的，且根据需要可以多次使用。</p>

<p>正如你预想的那样，与使用固定数量的计算步骤的固定网络相比，序列组织方法的操作要更为强大。RNN通过固定的（但可以学习的）函数把输入向量与其状态向量结合起来以产生新的状态向量。这在编程术语中可以被解释为，运行一个具有某些输入和一些内部变量的固定程序。从这个角度看，RNN本质上是在描述程序。事实上，就它可以模拟任意程序（使用恰当的权值向量）而言，<a href="http://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf">RNN是图灵完备的</a>。但是类似于神经网络的通用近似定理，你不用过于关注其中的细节。</p>

<blockquote>
<p>如果训练Vanilla神经网络是对函数进行优化，那么训练循环网络就是对程序进行优化。</p>
</blockquote>

<p>序列缺失下的序列化处理。你可能会想，将序列作为输入或输出是相当少见的，但重要的是要认识到，即使输入或输出是固定向量，你仍然可以使用这种强大的形式体系以序列化的方式对它们进行处理。例如，下图显示的结果来自<a href="https://deepmind.com/">DeepMind</a>的两篇非常不错的论文。在左边，算法学习一种循环网络策略，可以将它的注意力集中在图像周围。具体地说，就是它学习从左到右阅读门牌号码（<a href="https://arxiv.org/abs/1412.7755">Ba et al.</a>）。在右边，循环网络通过学习在画布上序列化地添加颜色来生成数字图像（<a href="https://arxiv.org/abs/1502.04623">Gregor et al.</a>）。</p>

<p><img src="/uploads/house-read.gif" alt="house-read">
<img src="/uploads/house-generate.gif" alt="house-generate"></p>

<p><em>左边：RNN学习阅读门牌号码。右边：RNN学习绘制门牌号码。</em></p>

<p>言外之意就是，即使数据不是序列的形式，你仍然可以制定和训练出强大的模型来学习序列化地处理它。你是在学习处理固定大小数据的有状态程序。</p>

<p>RNN计算。那么这些是如何工作的呢？主要是RNN有个看似简单的API：它接收输入向量x，然后给出输出向量y。然而最重要的是，该输出向量的内容不仅受到刚才输入的影响，还受到过去整个历史输入的影响。写成类的话，RNN的API由单个step函数构成。</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">rnn = RNN()
y = rnn.step(x)  # x是输入向量，y是RNN的输出向量
</code></pre></div>
<p>每当step函数被调用时，RNN的某些内部状态就会被更新。在最简单的案例中，这个状态由单个隐藏向量h构成。以下是Vanilla RNN中step函数的实现：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">class RNN:
  # ...
  def step(self, x):
    # update the hidden state
    self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))
    # compute the output vector
    y = np.dot(self.W_hy, self.h)
    return y
</code></pre></div>
<p>上面的代码详细说明了vanilla RNN的前向传播。这个RNN的参数是3个矩阵：W_hh、W_xh、W_hy。隐藏状态self.h被初始化为零向量。np.tanh函数实现一个非线性，将激活值压缩到范围[-1, 1]。注意代码是如何工作的：tanh内有两个条件，一是基于前面的隐藏状态，一是基于当前的输入。在NumPy中，np.dot是矩阵乘法。两个中间变量相加，然后被tanh压缩为新的状态向量。如果你更享受数学公式，我们也可以将隐藏状态写成：<img src="/uploads/equation.png" alt="equation">。</p>

<p>我们用随机数初始化RNN的矩阵，训练中的大部分工作是寻找那些能够产生期望行为的矩阵，通过一些损失函数来度量，这些函数表示对于输入序列x你偏好什么类型的输出y。</p>

<p>深度网络。RNN是神经网络，如果你进行深度学习并且开始像叠煎饼一样堆叠模型，它将会工作得越来越好（如果做得正确的话）。例如，我们可以通过以下方式建立一个2层的循环网络：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">y1 = rnn1.step(x)
y = rnn2.step(y1)
</code></pre></div>
<p>换句话说，我们有两个独立的RNN：一个RNN接收输入向量，而第二个RNN以第一个RNN的输出作为其输入。RNN其实并不关心这些——它们都只是向量的进出，以及在反向传播期间某些梯度流经每个模块。</p>

<p>需要指明的是，在实践中我们大多数人使用略有不同的长短期记忆（LSTM）网络。LSTM是一种特殊类型的循环网络，由于其强大的更新方程和一些吸引人的动态反向传播机制，它在实践中的效果略好一些。除了用于更新计算（self.h=...）的数学形式变得有点复杂外，其它所有都与本文介绍的RNN的内容完全相同。从这里开始，我会混合使用术语RNN和LSTM，但是本文中的所有实验都是用LSTM完成的。</p>

<h3 id="字符级别的语言模型">字符级别的语言模型</h3>

<p>现在我们已经知道RNN是什么，为什么它如此令人兴奋，以及它是如何工作的。我们现在就用它来实现一个有趣的应用：我们将训练RNN字符级别的语言模型。也就是说，我们提供RNN巨量的文本，然后让其建模，根据序列中以前的字符序列给出下一个字符的概率分布。这将允许我们一次一个字符地生成新文本。</p>

<p>作为示例，假设我们拥有只有四个字符“helo”的词汇表，想用训练序列“hello”训练一个RNN。这个训练序列实际上是4个独立的训练示例的来源：</p>

<ol>
<li>“h”出现时下一个字符最有可能是“e”。</li>
<li>“he”出现时下一个字符最有可能是“l”。</li>
<li>“hel”出现时下一个字符最有可能是“l”。</li>
<li>“hell”出现时下一个字符最有可能是“o”。</li>
</ol>

<p>具体来说，我们会使用1-of-k编码方式（即除对应字符为1外其余都为0）将每个字符编码成一个向量，并且使用step函数将它们一次一个地喂给RNN。然后，我们观察四维输出向量（每个字符一维）的序列，我们将其解释为RNN当前分配给序列中下次到来的每个字符的置信度。以下是示意图：</p>

<p><img src="/uploads/charseq.jpg" alt="charseq"></p>

<p>这个RNN示例具有4维输入和输出层，以及3个单位（神经元）的隐藏层。该示意图显示了当RNN把字符“hell”当作输入时前向传播中的激活值。输出层包含RNN为下一个字符分配的置信度（词汇表是“h,e,l,o”）。我们希望绿色数值尽可能高，红色数值尽可能低。</p>

<p>例如，我们可以看到，在第1个时间步骤中，当RNN看到字符“h”时，它将下一个可能出现字符的置信度分别设成“h”为1，“e”为2.2，“l”为-3.0，“o”为4.1。因为在训练数据（字符串“hello”）中，下一个正确的字符是“e”，所以我们希望增加其置信度（绿色）并降低所有其它字符的置信度（红色）。同样，在4个时间步骤中的每个步骤都有理想的目标字符需要网络给予更大的置信度。由于RNN完全由可微分的操作组成，我们可以运行反向传播算法（这只是微积分链式法则的递归应用）以计算出在哪个方向上我们应该调整其每个权重以增加正确目标（绿色粗体数值）的分数。我们然后可以执行参数更新，即在这个梯度方向上微调每个权重。如果我们在参数更新之后将相同的输入喂给RNN，我们会发现正确字符的分数（例如，第一个时间步骤中的“e”）将会略微变高（例如，从2.2变成2.3），而不正确字符的分数将会略微变低。然后我们重复这个过程多次直到网络收敛，并且它的预测最终与训练数据一致，即总能正确预测下一个字符。</p>

<p>更技术的解释是我们对每个输出向量同时使用标准的Softmax分类器（通常也称为交叉熵损失）。使用迷你批量的随机梯度下降训练RNN，并且我喜欢使用<a href="http://arxiv.org/abs/1502.04390">RMSProp</a>或Adam（每个参数的自适应学习速率方法）来稳定参数的更新。</p>

<p>另外要注意的是，输入字符“l”第一次的目标为“l”，但第二次为“o”。因此，RNN不能单独依赖输入，必须使用其循环连接来跟踪上下文以实现此任务。</p>

<p>在测试的时候，我们喂给RNN一个字符，并得到下次可能到来的字符的分布。我们从这个分布中取样，然后将其反馈给RNN以获得下一个字符。重复这个过程你就会得到文本！现在让我们在不同的数据集上训练RNN，看看会发生什么。</p>

<p>为了进一步说明，出于教育目的我还写过<a href="https://gist.github.com/karpathy/d4dee566867f8291f086">使用Python/NumPy的最小字符级别的RNN语言模型</a>。它只有大约100行左右，如果你更擅长阅读代码而不是文本，希望它能对上述内容给出一个简洁、具体和有用的总结。现在我们将深入实例结果，它由更高效的Lua/Torch代码库产生。</p>

<h3 id="rnn的乐趣">RNN的乐趣</h3>

<p>以下5个示例的字符模型都使用我在GitHub上发布的<a href="https://github.com/karpathy/char-rnn">代码</a>进行训练。每个案例中的输入都是单个文本文件，我们将训练RNN来预测序列中的下一个字符。</p>

<h4 id="paul-graham生成器">Paul Graham生成器</h4>

<p>让我们先尝试用一个小的英文数据集作为完整性检查。我最喜欢的数据集是<a href="http://www.paulgraham.com/articles.html">Paul Graham的文集</a>。基本想法是，这些文章中有很多的智慧，但不幸的是，Paul Graham的写作速度比较慢。如果我们可以根据需要生成创业智慧的样本，岂不美哉？这时就轮到RNN出场了。</p>

<p>合并Paul Graham过去5年的所有文章，我们可以得到大约1MB的文本文件，或者说大约100万个字符（顺便提一句，这是个非常小的数据集）。<em>技术：</em>训练一个2层的LSTM，含有512个隐藏节点（约350万个参数），每层之后有0.5的dropout。我们将通过每批次100个实例和长度为100个字符的截断式沿时间反向传播来训练。使用这些设置，每个批次在TITAN Z GPU上耗时大约0.46秒（这可以通过性能代价微不足道的50个字符的BPTT，即Backpropagation Through Time让耗时减半）。言归正传，让我们看看来自RNN的样本：</p>

<blockquote>
<p>The surprised in investors weren’t going to raise money. I’m not the company with the time there are all interesting quickly, don’t have to get off the same programmers. There’s a super-angel round fundraising, why do you can do. If you have a different physical investment are become in people who reduced in a startup with the way to argument the acquirer could see them just that you’re also the founders will part of users’ affords that and an alternation to the idea. [2] Don’t work at first member to see the way kids will seem in advance of a bad successful startup. And if you have to act the big company too.</p>
</blockquote>

<p>好吧，显然上面的样本暂时还无法取代Paul Graham，但是别忘了，RNN必须使用一个小的数据集（包括逗号，撇号和空格）完全从零开始学习英语。我也很喜欢它学会通过引用来支持自己的论点（例如上面的[2]）。有时候它会说一些有洞见的话，比如“a company is a meeting to think to investors”。如果你想看到更多，<a href="http://cs.stanford.edu/people/karpathy/char-rnn/pg.txt">这里</a>有5万个字符的样本。</p>

<p>温度。我们还可以在取样的时候调节Softmax的温度。将温度从1降至更低的数值（例如0.5）可以让RNN有更高的置信度，但其样本也会更保守。相反地，较高的温度将会带来更多的多样性，但是会以更多的错误为代价（例如拼写错误等）。特别是，将温度设置得非常接近于0时就会得到与Paul Graham更相似的言论：</p>

<blockquote>
<p>is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same</p>
</blockquote>

<p>看起来我们已经陷入了创业的死循环。</p>

<h4 id="莎士比亚">莎士比亚</h4>

<p>看起来RNN可以学习拼写英文单词。但是如果数据中有更多的结构和风格呢？为检验这一点，我下载了莎士比亚的所有作品，并将它们合并成单个（4.4MB）文件。现在我们可以训练一个更大的网络，在这个案例中，我们将尝试一个3层的RNN，每层有512个隐藏节点。在训练网络几个小时之后，我们得到如下的样本：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">PANDARUS:
Alas, I think he shall be come approached and the day
When little srain would be attain&#39;d into being never fed,
And who is but a chain and subjects of his death,
I should not sleep.

Second Senator:
They are away this miseries, produced upon my soul,
Breaking and strongly should be buried, when I perish
The earth and thoughts of many states.

DUKE VINCENTIO:
Well, your wit is in the care of side and that.

Second Lord:
They would be ruled after this chamber, and
my fair nues begun out of the fact, to be conveyed,
Whose noble souls I&#39;ll have the heart of the wars.

Clown:
Come, sir, I will make did behold your worship.

VIOLA:
I&#39;ll drink it.
</code></pre></div>
<p>记住，RNN只知道字符，所以它会对发言者的名字和内容进行取样。有时候我们也会得到相对延伸的独白短文，比如：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">VIOLA:
Why, Salisbury must find his flesh and thought
That which I am not aps, not a man and in fire,
To show the reining of the raven and the wars
To grace my hand reproach within, and not a fair are hand,
That Caesar and my goodly father&#39;s world;
When I was heaven of presence and our fleets,
We spare with hours, but cut thy council I am great,
Murdered and by thy master&#39;s ready there
My power to give thee but so much as hell:
Some service in the noble bondman here,
Would show him to her wine.

KING LEAR:
O, if you were a feeble sight, the courtesy of your law,
Your sight and several breath, will wear the gods
With his heads, and my hands are wonder&#39;d at the deeds,
So drop upon your lordship&#39;s head, and your opinion
Shall be against your honour.
</code></pre></div>
<p>我几乎不能把这些样本从莎士比亚的原作中辨别出来:)如果你喜欢莎士比亚，你可能会喜欢这<a href="http://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt">10万个字符的样本</a>。当然，你也可以使用我提供的代码在不同温度下生成无限数量的你自己的样本。</p>

<h4 id="维基百科">维基百科</h4>

<p>我们看到，LSTM可以学习拼写单词和复制一般的句法结构。让我们进一步增加难度，在结构化的markdown上面训练它。具体地说，就是使用<a href="http://prize.hutter1.net/">Hutter Prize</a> 的维基百科原始数据集（100MB）训练一个LSTM。和<a href="http://arxiv.org/abs/1308.0850">Graves et al.</a>一样，我使用前面的96MB来训练，剩下的用于验证以及在晚上跑几个模型。我们现在可以对维基百科的文章进行取样！以下是一些有趣的摘录：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Naturalism and decision for the majority of Arab countries&#39; capitalide was grounded
by the Irish language by [[John Clair]], [[An Imperial Japanese Revolt]], associated
with Guangzham&#39;s sovereignty. His generals were the powerful ruler of the Portugal
in the [[Protestant Immineners]], which could be said to be directly in Cantonese
Communication, which followed a ceremony and set inspired prison, training. The
emperor travelled back to [[Antioch, Perth, October 25|21]] to note, the Kingdom
of Costa Rica, unsuccessful fashioned the [[Thrales]], [[Cynth&#39;s Dajoard]], known
in western [[Scotland]], near Italy to the conquest of India with the conflict.
Copyright was the succession of independence in the slop of Syrian influence that
was a famous German movement based on a more popular servicious, non-doctrinal
and sexual power post. Many governments recognize the military housing of the
[[Civil Liberalization and Infantry Resolution 265 National Party in Hungary]],
that is sympathetic to be to the [[Punjab Resolution]]
(PJS)[http://www.humah.yahoo.com/guardian.
cfm/7754800786d17551963s89.htm Official economics Adjoint for the Nazism, Montgomery
was swear to advance to the resources for those Socialism&#39;s rule,
was starting to signing a major tripad of aid exile.]]
</code></pre></div>
<p>你可能会注意到，上面的雅虎网址实际上并不存在，是模型生造出来的。另外，还要注意到模型学会了正确地打开和关闭括号。模型学会的结构化markdown还有很多，比如有时候它会创建标题，列表等：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{ { cite journal | id=Cerling Nonforest Department|format=Newlymeslated|none } }
&#39;&#39;www.e-complete&#39;&#39;.

&#39;&#39;&#39;See also&#39;&#39;&#39;: [[List of ethical consent processing]]

== See also ==
*[[Iender dome of the ED]]
*[[Anti-autism]]

===[[Religion|Religion]]===
*[[French Writings]]
*[[Maria]]
*[[Revelation]]
*[[Mount Agamul]]

== External links==
* [http://www.biblegateway.nih.gov/entrepre/ Website of the World Festival. The labour of India-county defeats at the Ripper of California Road.]

==External links==
* [http://www.romanology.com/ Constitution of the Netherlands and Hispanic Competition for Bilabial and Commonwealth Industry (Republican Constitution of the Extent of the Netherlands)]
</code></pre></div>
<p>有时候，模型会生成随机但是有效的XML文件：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&lt;page&gt;
  &lt;title&gt;Antichrist&lt;/title&gt;
  &lt;id&gt;865&lt;/id&gt;
  &lt;revision&gt;
    &lt;id&gt;15900676&lt;/id&gt;
    &lt;timestamp&gt;2002-08-03T18:14:12Z&lt;/timestamp&gt;
    &lt;contributor&gt;
      &lt;username&gt;Paris&lt;/username&gt;
      &lt;id&gt;23&lt;/id&gt;
    &lt;/contributor&gt;
    &lt;minor /&gt;
    &lt;comment&gt;Automated conversion&lt;/comment&gt;
    &lt;text xml:space=&quot;preserve&quot;&gt;#REDIRECT [[Christianity]]&lt;/text&gt;
  &lt;/revision&gt;
&lt;/page&gt;
</code></pre></div>
<p>模型生成timestamp，id等等。另外，还要注意到它会以正确的嵌套顺序恰当地关闭相应的标签。如果你有兴趣看到更多，这里有<a href="http://cs.stanford.edu/people/karpathy/char-rnn/wiki.txt">10万个字符的维基百科样本</a>。</p>

<h4 id="代数几何（latex）">代数几何（Latex）</h4>

<p>以上结果表明，该模型在学习复杂句法结构方面确实相当擅长。这些结果令人印象深刻，我和我的实验室同事（<a href="http://cs.stanford.edu/people/jcjohns/">Justin Johnson</a>）决定在结构化的领域进一步推进。我们找到关于代数叠/几何的<a href="http://stacks.math.columbia.edu/">这本书</a>，下载它的原始Latex源文件（16MB），然后训练一个多层的LSTM。令人惊讶的是，产生的Latex样本几乎是可以编译的。在我们手动修复一些问题后，就得到了看起来似乎合理的数学推论，这是相当惊人的：</p>

<p><img src="/uploads/latex4.jpg" alt="latex4"></p>

<p><em>代数几何样本（假的），<a href="http://cs.stanford.edu/people/jcjohns/fake-math/4.pdf">这里是真正的PDF文件</a>。</em></p>

<p>这是另一份样本：</p>

<p><img src="/uploads/latex3.jpg" alt="latex3"></p>

<p><em>更像代数几何了，还出现了图表（右）。</em></p>

<p>正如你在上面看到的，有时候这个模型试图生成Latex图表，但显然它并不明白图表的具体意思。我也很喜欢它跳过证明的部分（左上角的“Proof omitted”）。当然，Latex有着相对困难的结构化语法格式，甚至我自己都没有完全掌握。例如，这里是一份来自模型的原始样本（未编辑）：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">\begin{proof}
We may assume that $\mathcal{I}$ is an abelian sheaf on $\mathcal{C}$.
\item Given a morphism $\Delta : \mathcal{F} \to \mathcal{I}$
is an injective and let $\mathfrak q$ be an abelian sheaf on $X$.
Let $\mathcal{F}$ be a fibered complex. Let $\mathcal{F}$ be a category.
\begin{enumerate}
\item \hyperref[setain-construction-phantom]{Lemma}
\label{lemma-characterize-quasi-finite}
Let $\mathcal{F}$ be an abelian quasi-coherent sheaf on $\mathcal{C}$.
Let $\mathcal{F}$ be a coherent $\mathcal{O}_X$-module. Then
$\mathcal{F}$ is an abelian catenary over $\mathcal{C}$.
\item The following are equivalent
\begin{enumerate}
\item $\mathcal{F}$ is an $\mathcal{O}_X$-module.
\end{lemma}
</code></pre></div>
<p>这份样本来自相对像样的模型，它展示了一些常见的错误。例如，模型打开一个\begin{proof}环境，但却以\end{lemma}结束。我们必须手动修复这种问题，它可能是由于依赖关系太长期的缘故：当模型完成proof的时候，它已经忘记是在做proof还是lemma。同样地，它打开一个\begin{enumerate}，但却忘记关闭它。我们观察到，在使用更大/更好的模型时，这些问题会变少，但尽管如此，这些问题还是会出现。</p>

<h4 id="linux源代码">Linux源代码</h4>

<p>我想把结构化的数据推到极限，所以最后的挑战是我决定使用代码。首先，我从<a href="https://github.com/torvalds/linux">GitHub上的Linux库</a>中提取所有的源文件和头文件，将它们合并成单个巨大的文件（474MB的C代码）（我本来只打算在内核上训练，但是其大小只有约16MB）。然后，我花几天的时间训练出几个大小刚好适合我的GPU的3层LSTM网络。这些模型有大约1000万个参数，对于RNN模型来说仍然很少。结果超级有趣：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">/*
 * Increment the size file of the new incorrect UI_FILTER group information
 * of the size generatively.
 */
static int indicate_policy(void)
{
  int error;
  if (fd == MARN_EPT) {
    /*
     * The kernel blank will coeld it to userspace.
     */
    if (ss-&gt;segment &lt; mem_total)
      unblock_graph_and_set_blocked();
    else
      ret = 1;
    goto bail;
  }
  segaddr = in_SB(in.addr);
  selector = seg / 16;
  setup_works = true;
  for (i = 0; i &lt; blocks; i++) {
    seq = buf[i++];
    bpf = bd-&gt;bd.next + i * search;
    if (fd) {
      current = blocked;
    }
  }
  rw-&gt;name = &quot;Getjbbregs&quot;;
  bprm_self_clearl(&amp;iv-&gt;version);
  regs-&gt;new = blocks[(BPF_STATS &lt;&lt; info-&gt;historidac)] | PFMR_CLOBATHINC_SECONDS &lt;&lt; 12;
  return segtable;
}
</code></pre></div>
<p>这些代码整体上看起来非常棒。当然，这些代码是不能够编译的，但是当你滚动这些生成的代码的时候，它给你的感觉非常像是一个巨大的C代码库。注意，RNN会随机地生成带有注释的代码。它很少会犯语法错误。比如，它能正确地使用字符串、指针表示法等。它也能正确地打开和关闭括号{[，学会很好地缩进代码。一个常见的错误是它不能跟踪变量：它经常使用未定义的变量（例如上面的rw），声明从不使用的变量（例如int error），或者返回不存在的变量。让我们看看更多的示例。这是另外一段代码，显示RNN学到的更多操作：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">/*
 * If this error is set, we will need anything right after that BSD.
 */
static void action_new_function(struct s_stat_info *wb)
{
  unsigned long flags;
  int lel_idx_bit = e-&gt;edd, *sys &amp; ~((unsigned long) *FIRST_COMPAT);
  buf[0] = 0xFFFFFFFF &amp; (bit &lt;&lt; 4);
  min(inc, slist-&gt;bytes);
  printk(KERN_WARNING &quot;Memory allocated %02x/%02x, &quot;
    &quot;original MLL instead\n&quot;),
    min(min(multi_run - s-&gt;len, max) * num_data_in),
    frame_pos, sz + first_seg);
  div_u64_w(val, inb_p);
  spin_unlock(&amp;disk-&gt;queue_lock);
  mutex_unlock(&amp;s-&gt;sock-&gt;mutex);
  mutex_unlock(&amp;func-&gt;mutex);
  return disassemble(info-&gt;pending_bh);
}

static void num_serial_settings(struct tty_struct *tty)
{
  if (tty == tty)
    disable_single_st_p(dev);
  pci_disable_spool(port);
  return 0;
}

static void do_command(struct seq_file *m, void *v)
{
  int column = 32 &lt;&lt; (cmd[2] &amp; 0x80);
  if (state)
    cmd = (int)(int_state ^ (in_8(&amp;ch-&gt;ch_flags) &amp; Cmd) ? 2 : 1);
  else
    seq = 1;
  for (i = 0; i &lt; 16; i++) {
    if (k &amp; (1 &lt;&lt; 1))
      pipe = (in_use &amp; UMXTHREAD_UNCCA) +
        ((count &amp; 0x00000000fffffff8) &amp; 0x000000f) &lt;&lt; 8;
    if (count == 0)
      sub(pid, ppc_md.kexec_handle, 0x20000000);
    pipe_set_bytes(i, 0);
  }
  /* Free our user pages pointer to place camera if all dash */
  subsystem_info = &amp;of_changes[PAGE_SIZE];
  rek_controls(offset, idx, &amp;soffset);
  /* Now we want to deliberately put it to device */
  control_check_polarity(&amp;context, val, 0);
  for (i = 0; i &lt; COUNTER; i++)
    seq_puts(s, &quot;policy &quot;);
}
</code></pre></div>
<p>注意，在第二个函数中，模型会比较tty == tty，这永远为真。另一方面，至少变量tty这次在函数范围内存在！在最后一个函数中，代码没有返回任何值，这是正确的，因为函数签名是void。但是，前面两个函数同样声明为void，确有返回值。这又是由于长期相互作用导致的常见错误。</p>

<p>有时候模型会决定是时候对新文件进行取样。这通常是非常有趣的部分：模型首先一个字符一个字符地复述GNU许可证，包含几个头文件，声明一些宏，然后就开始生成代码部分：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">/*
 *  Copyright (c) 2006-2010, Intel Mobile Communications.  All rights reserved.
 *
 *   This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 as published by
 * the Free Software Foundation.
 *
 *        This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *
 *  GNU General Public License for more details.
 *
 *   You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software Foundation,
 *  Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

#include &lt;linux/kexec.h&gt;
#include &lt;linux/errno.h&gt;
#include &lt;linux/io.h&gt;
#include &lt;linux/platform_device.h&gt;
#include &lt;linux/multi.h&gt;
#include &lt;linux/ckevent.h&gt;

#include &lt;asm/io.h&gt;
#include &lt;asm/prom.h&gt;
#include &lt;asm/e820.h&gt;
#include &lt;asm/system_info.h&gt;
#include &lt;asm/setew.h&gt;
#include &lt;asm/pgproto.h&gt;

#define REG_PG    vesa_slot_addr_pack
#define PFM_NOCOMP  AFSR(0, load)
#define STACK_DDR(type)     (func)

#define SWAP_ALLOCATE(nr)     (e)
#define emulate_sigs()  arch_get_unaligned_child()
#define access_rw(TST)  asm volatile(&quot;movd %%esp, %0, %3&quot; : : &quot;r&quot; (0));   \
  if (__type &amp; DO_READ)

static void stat_PC_SEC __read_mostly offsetof(struct seq_argsqueue, \
          pC&gt;[1]);

static void
os_prefix(unsigned long sys)
{
#ifdef CONFIG_PREEMPT
  PUT_PARAM_RAID(2, sel) = get_state_state();
  set_pid_sum((unsigned long)state, current_state_str(),
           (unsigned long)-1-&gt;lr_full; low;
}
</code></pre></div>
<p>这里面有太多有趣的地方需要涉及——仅仅这部分我大概就能写一整篇文章。现在我就不再多说，这里有<a href="http://cs.stanford.edu/people/karpathy/char-rnn/linux.txt">1MB的Linux代码样本</a>供你欣赏。</p>

<h4 id="生成婴儿名字">生成婴儿名字</h4>

<p>让我们尝试一个更好玩的。给RNN提供一个包含8000个婴儿名字的文本文件，每个名字一行（名字从<a href="http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/">这里</a>获得）。 我们可以把这些名字喂给RNN，然后生成新的名字！以下是一些示例名字，只显示训练数据中没有出现的（90%不会）：</p>

<p><em>Rudi Levette Berice Lussa Hany Mareanne Chrestina Carissy Marylen Hammine Janye Marlise Jacacrie Hendred Romand Charienna Nenotto Ette Dorane Wallen Marly Darine Salina Elvyn Ersia Maralena Minoria Ellia Charmin Antley Nerille Chelon Walmor Evena Jeryly Stachon Charisa Allisa Anatha Cathanie Geetra Alexie Jerin Cassen Herbett Cossie Velen Daurenge Robester Shermond Terisa Licia Roselen Ferine Jayn Lusine Charyanne Sales Sanny Resa Wallon Martine Merus Jelen Candica Wallin Tel Rachene Tarine Ozila Ketia Shanne Arnande Karella Roselina Alessia Chasty Deland Berther Geamar Jackein Mellisand Sagdy Nenc Lessie Rasemy Guen Gavi Milea Anneda Margoris Janin Rodelin Zeanna Elyne Janah Ferzina Susta Pey Castina</em></p>

<p>你可以在<a href="http://cs.stanford.edu/people/karpathy/namesGenUnique.txt">这里</a>看到更多。我最喜欢的名字包括“Baby”（哈哈）、“Killie”、“Char”、“R”、“More”、“Mars”、“Hi”、“Saddie”、“With”和“Ahbort”。这确实很有意思。当然，你还可以在写小说、命名或者给创业公司起名字的时候把它当作相当有用的灵感来源:)</p>

<h3 id="理解到底发生了什么">理解到底发生了什么</h3>

<p>我们看到，训练结束时的结果令人印象深刻，但是这些工作是如何进行的呢？让我们跑两个快速的实验来简单地窥视一下。</p>

<h4 id="训练中样本的演变">训练中样本的演变</h4>

<p>首先，看看样本文本在模型训练的过程中是如何演变的。例如，我用列夫·托尔斯泰的《战争与和平》来训练LSTM，然后每100次训练就产生一次样本。在第100次迭代时，模型取样的文本是随机杂凑的：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">tyntd-iafhatawiaoihrdemot  lytdws  e ,tfti, astai f ogoh eoase rrranbyne &#39;nhthnee e
plia tklrgd t o idoe ns,smtt   h ne etie h,hregtrs nigtike,aoaenns lng
</code></pre></div>
<p>但是请注意，至少它开始意识到单词要用空格分开。有时候它偶尔会插入两个空格。它也不知道逗号后面几乎总是有个空格。在迭代300次后，我们看到模型开始学会使用引号和句号：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;Tmont thithey&quot; fomesscerliund
Keushey. Thom here
sheulke, anmerenith ol sivh I lalterthend Bleipile shuwy fil on aseterlome
coaniogennc Phe lism thond hon at. MeiDimorotion in ther thize.&quot;
</code></pre></div>
<p>这些单词同样被空格分开，模型开始在句子结尾处使用句号。在第500次迭代时：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">we counter. He stutn co des. His stanted out one ofler that concossions and was
to gearang reay Jotrets and with fre colt otf paitt thin wall. Which das stimn
</code></pre></div>
<p>模式已经学会拼写最短和最常见的单词，如“we”、“He”、“His”、“Which”、“and”等。在第700次迭代时，我们开始看到越来越像英语的文本出现：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Aftair fall unsuch that the hall for Prince Velzonski&#39;s that me of
her hearly, and behs to so arwage fiving were to it beloge, pavu say falling misfort
how, and Gogition is so overelical and ofter.
</code></pre></div>
<p>在第1200次迭代时，我们看到引号、问号和感叹号的使用。同时还出现了更长的单词：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;Kite vouch!&quot; he repeated by her
door. &quot;But I would be done and quarts, feeling, then, son is people....&quot;
</code></pre></div>
<p>直到大约第2000次迭代时，我们才开始得到正确拼写的单词、引述、名字等等：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;Why do what that day,&quot; replied Natasha, and wishing to himself the fact the
princess, Princess Mary was easier, fed in had oftened him.
Pierre aking his soul came to the packs and drove up his father-in-law women.
</code></pre></div>
<p>从上面的描述可以知道，模型首先是发现单词-空格这样普遍的结构，然后迅速开始学习单词：首先从简短的单词开始，然后是更长的单词。跨越多个单词的话题和主题（以及一般的长期依赖关系）要到很久以后才会出现。</p>

<h4 id="可视化rnn中的预测与神经元激活">可视化RNN中的预测与神经元激活</h4>

<p>另一个有趣的可视化是看看字符的预测分布。在下面的可视化中，我们把验证集的字符数据（蓝色/绿色的行）喂给维基百科RNN模型，然后在每个字符下面可视化（用红色）前5个最有可能的下一个字符。颜色深浅由它们的概率大小决定（所以暗红色被认为是非常可能的，白色是不太可能的）。注意，有时候模型对下一个字符的预测是非常有信心的（例如，模型对<code>http://www.</code>序列中的字符就是）。</p>

<p>输入字符序列（蓝/绿）的颜色深浅取决于RNN隐藏层中随机选择的神经元的激活情况。绿色表示非常兴奋，蓝色表示不太兴奋（对于那些熟悉LSTM细节的人来说，这些是隐藏状态向量中[-1,1]之间的值，也就是经过门限操作和tanh计算的LSTM单元状态）。直观地说，这是在RNN读取输入序列的时候，将它的“大脑”中的一些神经元的激活率可视化。不同的神经元可能在寻找不同的模式。下面我们来看看4个不同的神经元，我认为它们是有趣的或者可解释的：</p>

<p><img src="/uploads/under1.jpg" alt="under1"></p>

<p><em>此图中高亮的神经元似乎对URL感到非常兴奋，在URL之外则不太兴奋。LSTM很可能使用这个神经元来记住它是否在URL内部。</em></p>

<p><img src="/uploads/under2.jpg" alt="under2"></p>

<p><em>当RNN在[[]]环境内时，此处高亮的神经元变得非常兴奋，在其外部则不太兴奋。有趣的是，神经元在看到字符“[”后不会兴奋，必须等待第二个“[”才能激活。计算模型是否已经看到一个或两个“[”的任务很可能用不同的神经元来完成。</em></p>

<p><img src="/uploads/under3.jpg" alt="under3"></p>

<p><em>在这里，我们看到神经元在跨越[[]]环境时似乎是线性变化的。换句话说，它的激活值给RNN提供了一个跨越[[]]范围的时间对齐的坐标系统。RNN可以使用这些信息来生成不同的字符，这或多或少可能取决于字符在[[]]范围内出现的早/晚（也许？）。</em></p>

<p><img src="/uploads/under4.jpg" alt="under4"></p>

<p><em>这里是另一个具有非常局部行为的神经元：它是相对安静的，但在碰到“www”序列中的第一个“w”之后立即变得不太兴奋。RNN可以使用这个神经元来计算它在“www”序列中有多远，以便它可以知道是否应该输出另一个“w”，或者是否应该开始URL。</em></p>

<p>当然，由于RNN的隐藏状态是极多的、高维的和分散的，所以这些结论有些需要手动调整。这些可视化是由自定义的HTML/CSS/JavaScript生成的，如果你想创建类似的东西，你可以看<a href="http://cs.stanford.edu/people/karpathy/viscode.zip">这里</a>的模板。</p>

<p>我们也可以通过排除最有可能的预测来精简这个可视化，仅仅显现文本，通过单元的激活值来决定颜色深浅。我们可以看到，除了大部分没有做任何解释的单元之外，大约5%的单元最终学会了相当有趣和可解释的算法：</p>

<p><img src="/uploads/pane1.png" alt="pane1">
<img src="/uploads/pane2.png" alt="pane2"></p>

<p>此外，在试图预测下一个字符（例如，它可能有助于跟踪你目前是否在引号内）的任何时候我们都不必硬编码，这是多么美妙的一件事情！我们刚刚使用原始数据训练LSTM，它就决定这是个有用的东西需要跟踪。换句话说，其中一个单元在训练中逐渐把自己调整成为引号检测单元，因为这有助于它更好地完成最终任务。这是深度学习模型（更普遍的端到端训练）的能力来自哪里的最干净和最引人注目的示例之一。</p>

<h3 id="源代码">源代码</h3>

<p>希望我已经让你深信，训练字符级别的语言模型是一个非常有趣的练习。你可以使用我在GitHub上发布的<a href="https://github.com/karpathy/char-rnn">字符RNN代码</a>（采用MIT许可证）来训练自己的模型。它需要一个大的文本文件来训练字符级别的模型，然后你就可以从中取样。此外，如果你有一个GPU的话会更好，否则在CPU上训练会多花大约10倍的时间。不管怎样，如果你用某些数据进行训练并最终得到有趣的结果，请告诉我！如果你迷失在Torch/Lua的代码库中，请记住，它只是这<a href="https://gist.github.com/karpathy/d4dee566867f8291f086">100行要点</a>的更高级版本。</p>

<p><em>题外话。</em>代码是用<a href="http://torch.ch/">Torch 7</a>编写的，它最近已经成为我最喜欢的深度学习框架。我在最近的几个月才开始使用Torch/Lua，它们并不简单（我花了很多时间在GitHub上挖掘原始的Torch代码，并在gitter上询问他们问题以完成工作），但是一旦你掌握了足够的知识，它就会给你带来很大的灵活性和速度提升。我以前同样使用过Caffe和Theano，我认为，虽然Torch还不完美，但是它的抽象层次和哲学要比其它的好。在我看来，一个高效的框架应该具有以下特征：</p>

<ol>
<li>具有许多功能的CPU/GPU透明张量库（切片、数组/矩阵操作等）</li>
<li>一套基于脚本语言（最好是Python）的完全独立的代码库，能够对张量进行操作，实现所有深度学习的东西（前向/反向传播、图计算等）</li>
<li>可以轻松地分享预训练的模型（Caffe做的很好，其它的不行）</li>
<li>最关键的：没有编译步骤（或者至少不要像Theano现在这样）。深度学习的趋势是更大更复杂的网络，它们在复杂图中花费的时间会成倍地增加。不需要长时间编译或开发是非常重要的。其次，编译会丢失可解释性和有效日志/调试的能力。如果有选项可以在图被开发完成后选择是否编译，那是相当好的。</li>
</ol>

<h3 id="进一步阅读">进一步阅读</h3>

<p>在结束这篇文章前，我还想把RNN放到更广泛的背景中，并提供当前研究方向的概述。RNN最近在深度学习领域颇受欢迎。和卷积网络类似，它已经存在了几十年，但是它的全部潜力最近才开始得到广泛的认可，这在很大程度上是由于我们不断增长的计算资源。这里简要概述一些最近的发展情况（肯定不是完整的清单，很多这样的工作可以追溯到20世纪90年代的研究，请参阅相关的研究部分）：</p>

<p>在NLP/语音领域，RNN<a href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf">将语音转录为文本</a>，执行<a href="http://arxiv.org/abs/1409.3215">机器翻译</a>，<a href="http://www.cs.toronto.edu/%7Egraves/handwriting.html">生成手写文本</a>，当然，它也被用作强大的语言模型（<a href="http://www.cs.utoronto.ca/%7Eilya/pubs/2011/LANG-RNN.pdf">Sutskever et al.</a>）（<a href="http://arxiv.org/abs/1308.0850">Graves</a>）（<a href="http://www.rnnlm.org/">Mikolov et al.</a>）（都是在字符和单词层面）。目前看来，单词级别的模型比字符级别的模型更好，但这肯定是暂时的。</p>

<p>计算机视觉。RNN在计算机视觉中也很快变得普及。例如，将RNN用于帧级别的<a href="http://arxiv.org/abs/1411.4389">视频分类</a>，<a href="http://arxiv.org/abs/1411.4555">图像标注</a>（也包括我自己的工作以及其它许多内容），<a href="http://arxiv.org/abs/1505.00487">视频标注</a>以及最近的<a href="http://arxiv.org/abs/1505.02074">视觉问答</a>。在计算机视觉论文中，我个人最喜欢的RNN是<a href="http://arxiv.org/abs/1406.6247">可视化注意力的循环模型</a>，这是由于其高层次的方向（对图像扫视后的序列化处理）和低层次的建模（REINFORCE学习规则是强化学习中策略梯度方法的一个特例，可以训练出执行不可微分计算的模型（在这种情况下对图像周围进行扫视））。我相信，这种由CNN做原始感知加上RNN在顶部做扫视策略的混合模型将变得普及，特别是在那些不仅仅是对普通视图中某些对象进行分类的更复杂的任务中。</p>

<p>归纳推理、记忆和注意力。另一个极其令人兴奋的研究方向是面向解决Vanilla循环网络的局限性。RNN的一个问题是不具有归纳性：它能很好地记忆序列，但不一定总是以正确的方式显示令人信服的泛化符号。第二个问题是它不必要地将表征大小与每个步骤的计算量相结合。例如，如果将隐藏状态矢量的大小加倍，由于矩阵乘法的原因，每个步骤的FLOPS（译者注：浮点运算时间）数量会增加四倍。理想情况下，我们希望在保持巨大的表征/记忆（例如，包含所有维基百科或许多中间状态变量）的同时，能够保持每个时间步骤的计算量固定不变。</p>

<p>在这些方向上，第一个有说服力的示例已经在DeepMind的<a href="http://arxiv.org/abs/1410.5401">神经图灵机</a>论文中被建立。论文勾勒出一个模型的路径，该模型可以在大型外部存储阵列和较小的记忆寄存器集（运算发生的地方，可以将其视作我们的工作记忆）之间执行读/写操作。至关重要的是，该论文还特别提出一个非常有趣的记忆寻址机制，该机制是通过（“软”的和完全可微分的）注意力模型来实现的。“软”注意力的概念已被证明是一个强大的建模特性，也被<a href="http://arxiv.org/abs/1409.0473">通过共同学习对齐和翻译的神经机器翻译</a>提出用于机器翻译和被<a href="http://arxiv.org/abs/1503.08895">记忆网络</a>提出用于（玩具）问答。事实上，我可以这么说：</p>

<blockquote>
<p>注意力的概念是近期神经网络中最有趣的架构创新。</p>
</blockquote>

<p>现在，我不想讲太多的细节，但是记忆寻址的“软”注意力方案是很方便的，因为它使得模型完全可微分的，但不幸的是会牺牲一些效率，因为所有可以被注意的东西都被注意到了。可以将其视作C语言中的指针，它不指向特定地址，而是定义了整个记忆地址，并且间接引用指针，返回指向内容的权重和（这是非常昂贵的操作！）。这让很多研究者从“软”注意力模型转向“硬”注意力模型，以便对某个特定的需要注意的记忆块进行采样（例如，在某种程度上对某些记忆单元读/写而不是对所有单元读/写）。这个模型在哲学上更有吸引力、可扩展和高效，但不幸的是它也是不可微分的。这就要求使用来自强化学习文献（例如REINFORCE）的技术，其中人们完全习惯于不可微分的相互作用的概念。这项工作现在还在进展中，但是这些“硬”注意力模型已经被探索过，例如，<a href="http://arxiv.org/abs/1503.01007">使用栈增强循环网络的推理算法模式</a>、<a href="http://arxiv.org/abs/1505.00521">强化学习神经图灵机</a>和<a href="http://arxiv.org/abs/1502.03044">Show Attend and Tell</a>。</p>

<p>研究者。如果你想详细研究RNN，我推荐<a href="http://www.cs.toronto.edu/%7Egraves/">Alex Graves</a>、<a href="http://www.cs.toronto.edu/%7Eilya/">Ilya Sutskever</a>和<a href="http://www.rnnlm.org/">Tomas Mikolov</a>的论文。想要知道更多关于REINFORCE和更通用的强化学习和策略梯度方法（REINFORCE是它的一个特例）的内容，可以学习<a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Home.html">David Silver</a>或者<a href="http://www.cs.berkeley.edu/%7Epabbeel/">Pieter Abbeel</a>的公开课。</p>

<p>代码。如果你想训练RNN，Theano上的<a href="https://github.com/fchollet/keras">Keras</a>或<a href="https://github.com/IndicoDataSolutions/Passage">Passage</a>很不错，或者是本文配套的<a href="https://github.com/karpathy/char-rnn">Torch代码</a>，或者是我不久以前写的原始NumPy代码的<a href="https://gist.github.com/karpathy/587454dc0146a6ae21fc">要点</a>，它实现了一个高效、批量的LSTM前向和反向传播。你也可以看看我的基于NumPy的<a href="https://github.com/karpathy/neuraltalk">NeuralTalk</a>，它使用RNN/LSTM来标注图像，或者看看Jeff Donahue的这个<a href="http://jeffdonahue.com/lrcn/">Caffe实现</a>。</p>

<h3 id="总结">总结</h3>

<p>我们已经学习了RNN，它是如何工作的，以及为什么它如此重要。我们还使用几个有趣的数据集来训练RNN字符级别的语言模型，并且我们已经看到RNN是如何进行这个过程的。你可以自信地期待RNN领域的大量创新，我相信它将成为智能系统的普遍和关键组成部分。</p>

<p>最后，为给这篇文章增加一些元素，我使用这篇博文的源文件来训练一个RNN。不幸的是，文章的长度不足以很好地训练RNN。以下是返回的样本（使用低温生成以获得更典型的样本）：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">I&#39;ve the RNN with and works, but the computed with program of the
RNN with and the computed of the RNN with with and the code
</code></pre></div>
<p>是的，这篇文章讲的是RNN以及它的效果如何，很明显它工作良好:)下次再见！</p>

<p>额外链接：</p>

<p>视频:</p>

<ul>
<li>我在<a href="https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks">伦敦深度学习会议（视频）</a>上关于这项工作发表的讲话。</li>
</ul>

<p>讨论:</p>

<ul>
<li><a href="https://news.ycombinator.com/item?id=9584325">HN上的讨论</a></li>
<li>Reddit的<a href="http://www.reddit.com/r/MachineLearning/comments/36s673/the_unreasonable_effectiveness_of_recurrent/">r/machinelearning</a>上的讨论</li>
<li>Reddit的<a href="http://www.reddit.com/r/programming/comments/36su8d/the_unreasonable_effectiveness_of_recurrent/">r/programming</a>上的讨论</li>
</ul>

<p>回复:</p>

<ul>
<li><a href="https://twitter.com/yoavgo">Yoav Goldberg</a>把这些RNN结果和<a href="http://nbviewer.ipython.org/gist/yoavg/d76121dfde2618422139">n-gram最大似然（计数）基线</a>做比较</li>
<li><a href="https://twitter.com/nylk">@nylk</a>使用<a href="https://gist.github.com/nylki/1efbaa36635956d35bcc">烹饪食谱</a>训练字符RNN。它看起来非常棒！</li>
<li><a href="https://twitter.com/MrChrisJohnson">@MrChrisJohnson</a>使用Eminem的歌词训练字符RNN，然后合成一首说唱歌曲并用机器声音演唱它。极其滑稽的:)</li>
<li><a href="https://twitter.com/samim">@samim</a>使用<a href="https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0">奥巴马的演讲</a>训练字符RNN。它看起来很有趣！</li>
<li><a href="https://twitter.com/seaandsailor">João Felipe</a>使用爱尔兰民间音乐训练字符RNN，这里是<a href="https://soundcloud.com/seaandsailor/sets/char-rnn-composes-irish-folk-music">音乐样本</a></li>
<li><a href="https://twitter.com/boblsturm">Bob Sturm</a>使用<a href="https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/">ABC记谱法的音乐</a>训练字符RNN</li>
<li><a href="https://twitter.com/the__glu/with_replies">Maximilien</a>的<a href="https://twitter.com/RNN_Bible">RNN圣经机器人</a></li>
<li><a href="http://cpury.github.io/learning-holiness/">这篇博文</a>介绍如何使用RNN学习《圣经》</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[追逐时髦的技术]]></title>
    <link href="http://codemany.com/blog/chasing-the-shiny-and-new-in-software/"/>
    <updated>2017-08-29T11:50:09+08:00</updated>
    <id>http://codemany.com/blog/chasing-the-shiny-and-new-in-software</id>
    <content type="html"><![CDATA[<p>英文原文：<a href="https://www.nemil.com/musings/shinyandnew.html">https://www.nemil.com/musings/shinyandnew.html</a></p>

<p>有关当前最好的框架或编程语言的争论经常发生在Web开发中。就这点而言，<a href="https://www.scribd.com/">Scribd</a>的联合创始人Jared Friedman在2015年写了<a href="http://blog.jaredfriedman.com/2015/09/15/why-i-wouldnt-use-rails-for-a-new-company/">一篇文章</a>推荐创业公司使用Node.js代替Rails。</p>

<p>他提出几个关键点：</p>

<ul>
<li>Rails很慢。</li>
<li>黑客学院的毕业生都在使用Rails，贬低了它对高级工程师的价值，并减少了它的未来前景。</li>
<li>创业公司应该使用那些前瞻性工程师今后将使用的技术，以保证它们的应用不过时。</li>
<li>在Scribd，过去几年里它们已经从Prototype转换到jQuery，再到CoffeeScript，再到Angular，再到React。</li>
</ul>

<p>Node.js是创业公司的绝佳选择，但它饱受批评的两个部分令我担忧。首先，一名创业公司的工程师应该了解什么技术将会在几年后流行，以保证它们的技术栈不过时。第二，杰出的软件工程师将被时髦的技术栈吸引到创业公司，而不是有趣的技术问题。在过去我还听到过更恶劣的传闻，创业公司的开发者拒绝接受使用ES5 JavaScript编程的工作（那时CoffeeScript刚出来），Mongo发布不久工程师就执意在生产环境下使用Mongo替代Postgres，渴望用最新的前端框架不断重构项目。</p>

<p>我担心有些程序员（和他们的雇主）有这种倾向，即把注意力放在转换技术栈到最新上。他们主要基于框架选择公司，力求在工作中使用最新而不是最好的工具。他们把时间花在新的库和框架上，而不是提高他们的核心技术能力。我们把他们称为技术栈追逐者——他们奋力追求在创业公司的技术栈中使用那些对核心输出（用户重视的软件功能、开发团队的生产力）提升有限的新技术（或者他们自己喜欢的技术）。</p>

<h3 id="“时髦的”web开发">“时髦的”Web开发</h3>

<p>很同情那些在<a href="https://news.ycombinator.com/">Hacker News</a>上的时髦的Web或移动应用开发者。作为在2012年的全栈创业公司的开发者，你正在构建后端使用Ruby/Rails，前端使用Backbone/CoffeeScript/Underscore的网站，同时使用Capistrano（或相关的Python类似物）部署你的应用。到2013年，你已经将后端转换到Node/Express/Mongo，前端为Grunt/Ember。在2014年，你已经彻底切换到MEAN技术栈，但在尝试过Koa以后考虑转移到Go（在Express核心贡献者<a href="https://medium.com/@tjholowaychuk/farewell-node-js-4ba9e7f3e52b">告别Node.js转向Go</a>以后）。在2015年，你在后端使用Express/Go，前端使用Gulp/ES2015/React，使用React Native代替原生移动语言，并且慢慢地将系统转换为使用Docker的微服务。很快，你将会被转换到Phoenix，如果Angular 2是正确的选择也会转换过去——甚至可能创造一个Go可以工作在Android上以及开源Swift可以适合你的技术栈的世界。（我显然是夸大效果，尽管这是HN头条新闻流行什么的一个合理表示。）</p>

<p>有几个原因表明这可能是合理的。时髦的Web工程师需要“时尚”才能获得未来的工作或合同。雇主使用框架或语言作为过滤器，而不是测试批判性思维和技能。雇主没有意识到有实力的开发者如果有正确的支持，可以在几个星期，通常是几天内成为许多语言或者框架的专家。有时趋势是无法阻止的：Swift正在取代Objective-C，世界正在转向更薄、更小的单体后端和更重、反应更灵敏的前端。通常，转变有着巨大的优势：生产力大幅上升，或者新的用户功能突然变得可能。然而，所有的变化都不会导致早期到中期的公司不采用就死，而为了乐趣或业余项目学习技术和认为它是生产环境的关键是迥然不同的。</p>

<p>我们可以用创业公司的时髦的Web或移动开发者与我们的计算机科学家作为对比。我的一个朋友是一家顶级科技公司的计算机神经学家——跟几乎所有从事技术工作的人一样，他的世界每隔几个月就会被重塑——得益于计算能力、脑成像和深度学习算法的快速发展。基本的编程工具其实变化不大。公平地说，只有C++从 11转换到14引起了一些焦虑。还有分布式计算系统、键/值存储和其它外部服务，但这些都是使用稳定的API构建的。他的大部分时间都花在单个DSL中的架构和算法上，而不是重写功能相似的代码或者快速学习提供有争议的好处和改变的库。</p>

<h3 id="选择工具">选择工具</h3>

<p>人们可能会建议创业公司选择时髦的技术栈，因为它是招聘杰出的工程师的关键工具。我自己的观察是，杰出的工程师注重其它的东西。到目前为止，最重要的是提供有趣的问题去解决——有趣的人与他们合作。吸引力和强大的使命感是吸引优秀人才（工程师或者其他）的其它途径。</p>

<p>我并不是在抱怨技术发展太快，也不是说我们都应该用汇编语言或者C++或者Ruby编程。软件工程师清楚他们的目标——我们的领域以令人目眩的速度发展，但对于我们拥有的影响力这都是值得的，因为有10亿人上网。我认为你需要有能力快速地学会新的框架、语言或库（如何完成它的<a href="https://news.ycombinator.com/item?id=7733249">Ask HN</a>）——依靠周围那些经验丰富的工程师，你的目标应该是尽快地具有生产力。除此之外，你应该深刻理解多种语言，而不仅仅是一种（但是同样的态度，不应盲目地扩展到框架或者轻量级的DSL）。</p>

<p>对于创业公司而言，Paul Graham<a href="http://castig.org/an-interview-with-paul-graham-hackers-painters-10-years-later/">在2013年被问到关于理想的语言</a>：“我的意思是，我们有的创业公司在用PHP编写代码——这让我有点担心，但这并不像其它事情那么让我担心。”GitHub的技术主管Sam Lambert在<a href="https://medium.com/s-c-a-l-e/github-scaling-on-ruby-with-a-nomadic-tech-team-4db562b96dcd">最近的一次采访</a>中谈到，他在2013年被GitHub的CTO面试时，对GitHub的技术栈是Rails、C和Bash脚本感到惊讶：“随着面试的继续，我发现他们实际上是一群非常务实的黑客，他们只钻研Ruby和C，使用更稳定的技术栈以便花时间工作在更有趣的事情上，而不是追逐最新最酷炫的技术。”GitHub的方法在我看来是Web和移动开发者的合理的平衡：广泛地探索工具，然后务实地选择解决你所面临的问题的工具（<a href="https://martinfowler.com/bliki/Yagni.html">YAGNI</a>适用于更多的地方，而不仅仅是面向用户的功能开发）。</p>

<p>令我担心的是，某些开发者，特别是在职业生涯早期的开发者，可能会以为创业公司的工程师不是问题解决者或计算机科学家，而是一个荣誉查找表——他们的任务是每隔几个月记住一个新的DSL——只能获得有限的好处。这使我们这些早期的工程师贬值——构建人们想要的东西，从事有趣的技术问题，快速交付代码。</p>

<p>无论如何，要在额外的时间里广泛地实践。如果好处是压倒性的，则切换生产环境中的语言/框架，但要考虑是哪些好处。警惕那些追求新技术却不考虑它对团队的预期优势的人。花时间学习概念和解决有趣的技术或用户问题。如果你有正确的应用边界，并选择你有现成生产力的框架，一旦你这样做了，你将具有一定的灵活性，但需要足够坚持才能达到产品与市场的匹配和超越。</p>

<p>任何一天打开<a href="https://news.ycombinator.com/">Hacker News</a>，你都能看到有帖子诱惑你使用某个框架、语言、类库或者服务去贡献和构建应用（包括一些像Mongo这样有大笔现金的公司，因此在它们的平台后面有营销预算）。有些工具拥有改变游戏规则的能力，其余的只有一些关键的不同功能，但是它们都需要时间才能成为专家。有些工具会大声宣告它们才是未来，并且嘲笑你所学到的东西——但是它们需要你的技能和意识与现有的技术真正地竞争。你会如何选择？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[checked/unchecked应该翻译成什么？]]></title>
    <link href="http://codemany.com/blog/what-should-checked-and-unchecked-translate/"/>
    <updated>2017-07-29T12:17:06+08:00</updated>
    <id>http://codemany.com/blog/what-should-checked-and-unchecked-translate</id>
    <content type="html"><![CDATA[<p>翻译有关Java异常的文章时，总是犹豫是否该把checked/unchecked也翻译过来。原因是，不是很清楚该如何优雅传神地翻译这两个单词。</p>

<p>《Java核心技术》将它们翻译成“已检查/未检查”。《Java编程思想》和《Effictive Java中文版》则翻译成“被检查的/不检查的”。至于技术文章的翻译更是花样百出，有“检测/非检测”、“可检测/非检测”、“可查/不可查”、“受查/非受查”、“检查型/非检查型”、“检查/非检查”等。</p>

<p>到底该翻译成什么呢？在回答这个问题前，让我们先确定什么是checked/unchecked异常？</p>

<p><img src="/uploads/exception-hierarchy.png" alt="exception-hierarchy"></p>

<p>上图是Java中的异常层次结构图。Java语言规范将派生自RuntimeException类和Error类的所有异常称为“unchecked异常”，其它的异常称为“checked异常”。</p>

<blockquote>
<p>The unchecked exception classes are the run-time exception classes and the error classes.</p>

<p>The checked exception classes are all exception classes other than the unchecked exception classes. That is, the checked exception classes are Throwable and all its subclasses other than RuntimeException and its subclasses and Error and its subclasses.</p>
</blockquote>

<p>并且，在编译时编译器会检查程序是否为所有的“checked异常”提供处理器。</p>

<blockquote>
<p>This compile-time checking for the presence of exception handlers is designed to reduce the number of exceptions which are not properly handled.</p>
</blockquote>

<p>从上述的描述可以得出，“checked异常”和“unchecked异常”是两种异常类型，且“checked异常”隐含有必须要检查的思想。</p>

<p>紧紧围绕这些描述，细细地思考和比较，个人认为：1. 《Java核心技术》的翻译存在问题，“已检查”和“未检查”说明的是异常的检查状态，没有表达出异常的分类这个概念。2. 《Java编程思想》和《Effictive Java中文版》的翻译则正确地表达了异常的分类，但“被检查”翻译的有点无厘头，如果能改成“要检查”则会更好，缺陷是连接“异常”这个词组后是短语，而非名词，读来费劲，也不上口；如果去掉“的”的话，后者会有歧义，听起来像是命令。3. “检测/非检测”和“检查/非检查”是同个意思。4. “可检测”这个翻译看上去似乎表示异常是可以检查的，和Java语言规范要求的该类异常必须要检查不符。5. “可查/不可查”也是如此。6. “受查/非受查”的翻译则有些莫名其妙的感觉。7. “检查型/非检查型”翻译的很好，既表达了异常的分类，也表达了一种异常是要检查的，另一种异常是不要检查的意义，只是前者还缺少点强制的意味。</p>

<p>分析到这里，结果已经是不言而明。“要检查的/不检查的”和“检查型/非检查型”是两种更好的翻译，都能把Java语言规范对checked/unchecked异常的描述尽量地表述出来。而后者在实际使用中更为简洁适宜。</p>

<p>接下来的事情就是把以前译文中未翻译的checked/unchecked修改成“检查型/非检查型”。在以后的翻译中也继续使用这个翻译结果，除非能找到更好的表述方式。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[费曼技巧：最好的学习方法]]></title>
    <link href="http://codemany.com/blog/learn-anything-faster-with-the-feynman-technique/"/>
    <updated>2017-06-02T08:30:09+08:00</updated>
    <id>http://codemany.com/blog/learn-anything-faster-with-the-feynman-technique</id>
    <content type="html"><![CDATA[<p>英文原文：<a href="https://www.farnamstreetblog.com/2012/04/learn-anything-faster-with-the-feynman-technique/">https://www.farnamstreetblog.com/2012/04/learn-anything-faster-with-the-feynman-technique/</a></p>

<p>费曼技巧有4个简单的步骤，我将在下面解释它们：</p>

<ul>
<li>选择一个概念</li>
<li>把它教给某个小孩</li>
<li>识别薄弱环节，回到原始材料</li>
<li>回顾和简化（可选）</li>
</ul>

<p>如果你不学习就会固步自封。那么，学习新主题并识别现有知识的薄弱环节的最好方式是什么？</p>

<h3 id="两种类型的知识">两种类型的知识</h3>

<p>有<a href="https://www.farnamstreetblog.com/2015/09/two-types-of-knowledge/">两种类型的知识</a>，我们大多数人关注错误的那种。第一类知识注重知道某事物的名称。第二类注重知道某事物。它们不是一回事。著名的诺贝尔物理学奖获得者理查德·费曼（Richard Feynman）明白<a href="https://www.farnamstreetblog.com/2015/01/richard-feynman-knowing-something/">知道某事物和知道某事物的名称之间的差异</a>，这是他成功的最重要的原因之一。事实上，他创造了一个学习公式，确保他比其他人更明白某些东西。</p>

<p>这被称为费曼技巧，它将帮助你更快更明白地学到东西。最重要的是，它极其容易实现。</p>

<blockquote>
<p>一个人如果说他知道他在想些什么，却表达不出来，通常是他其实并不知道自己在想些什么。——莫提默·艾德勒</p>
</blockquote>

<h3 id="费曼技巧">费曼技巧</h3>

<p>费曼技巧有4个步骤。</p>

<h4 id="步骤1：把它教给某个小孩">步骤1：把它教给某个小孩</h4>

<p>拿出一张白纸，在顶部写下你想要学习的主题。写出你对这个主题的了解，好像你正在把它教给某个小孩。不是你聪明的成年朋友，而是一个8岁的小孩，他刚好有足够的词汇和注意力来涵盖基本的概念和关系。</p>

<p>很多人倾向于使用复杂的词汇和行话来掩盖他们不明白的东西。问题是我们仅仅愚弄自己，因为我们不知道我们不明白。另外，使用行话会掩盖周围的人对我们的误解。</p>

<p>当你自始至终都用孩子可以理解的简单的语言写出某个想法时（提示：只用最常见的单词），你迫使自己在更深的层次上去理解这个概念，并简化想法之间的关系和连接。如果你努力，你会清楚地知道自己在哪里还有薄弱环节。这种压力很好——它预示着学习的机会。</p>

<h4 id="步骤2：回顾">步骤2：回顾</h4>

<p>在第一步中，你不可避免地会遇到你的知识的薄弱环节，你忘记了某些重要的东西，或者不能解释它，或者只是很难把重要的概念联系起来。</p>

<p>这是宝贵的反馈，因为你已经发现你的知识的边缘。胜任力是知道你能力的极限，你刚刚已经识别出一个！</p>

<p>这是学习开始的地方。现在你知道在哪里会遇到困难，回到原始材料并重新学习，直到你可以用基本的术语去解释它们。</p>

<p>识别你的理解的边界也限制了你可能犯的错误，并增加了在应用知识时成功的机会。</p>

<h4 id="步骤3：整理和简化">步骤3：整理和简化</h4>

<p>现在你有一套手工制作的笔记。检查它们以确保你没有错误地从原始材料中借用任何行话。将它们组织成一个丰满的简单的故事。</p>

<p>把它们大声地朗读出来，如果解释不直白或者听起来很混乱，这表明你在该领域的理解仍需要做些工作。</p>

<h4 id="步骤4（可选）：传播">步骤4（可选）：传播</h4>

<p>如果你真的想要确保自己的理解没有任何偏差，那就把它告诉别人（理想状态是这个人对该主题知之甚少，或者就找个8岁的小孩）。对你的知识的最终考验是你将其传达给另一个人的能力。</p>

<p>这不仅是学习的一个妙诀，它也是一种不同的思维方式的窗口，允许你将想法分解，然后从头开始重建。（Elon Musk称它为<a href="https://www.farnamstreetblog.com/2015/04/elon-musk-framework-thinking/">从第一个原则思考</a>）。这会导致对想法和概念的更深入的理解。重要的是，以这种方式解决问题，你可以在别人不知道他们自己在说什么的情况下理解这个问题。</p>

<p>费曼的方法直观地认为智力是一个成长的过程，这与卡罗尔·德韦克（Carol Dweck）的工作非常吻合，卡罗尔·德韦克漂亮地描述了<a href="https://www.farnamstreetblog.com/2015/03/carol-dweck-mindset/">固定型和成长型思维之间的区别</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[100%代码覆盖率的悲剧]]></title>
    <link href="http://codemany.com/blog/code-coverage-100-percent-tragedy/"/>
    <updated>2017-05-13T19:00:41+08:00</updated>
    <id>http://codemany.com/blog/code-coverage-100-percent-tragedy</id>
    <content type="html"><![CDATA[<p>英文原文：<a href="http://labs.ig.com/code-coverage-100-percent-tragedy">http://labs.ig.com/code-coverage-100-percent-tragedy</a></p>

<p>有趣的是，我对测试的观点正在发生变化。十五年来，我一直在宣扬TDD（测试驱动开发，或者被称为测试先行方法），或至少让开发者写些单元测试。不过，最近我发现自己更经常地说，“你为什么要写测试？”而不是“你应该写测试”。</p>

<h3 id="怎么回事？">怎么回事？</h3>

<p>在办公室四处走走时，开发者要求我帮助他进行单元测试。看来他在使用Mockito测试以下代码时遇到了麻烦：</p>

<p><img src="/uploads/initialise-method.png" alt="initialise-method"></p>

<p>我想他是非常惊讶于我的回应：“你不需要测试。”</p>

<p>“但我不得不测啊！”他说。“否则如何知道这段代码是正常的？”</p>

<p>“这段代码很明显。没有条件，没有循环，没有转换，没有任何东西。它们只是一些普通的旧式胶水代码。”</p>

<p>“但没有测试，任何人都可以来修改和破坏这段代码呀！”</p>

<p>“看，如果那个虚构的邪恶/无知的开发者来了，破坏了这些简单的代码，如果相关的单元测试中断，你认为他会做什么？他只会删除它。”</p>

<p>“但是如果非要写测试怎么办？”</p>

<p>“在这种情况下，我将这样写测试：”</p>

<p><img src="/uploads/initialise-test.png" alt="initialise-test"></p>

<p>“但是你没有使用Mockito啊！”</p>

<p>“那又怎么样呢？Mockito没有帮助你。恰恰相反：它会妨碍你，并且它也不会使测试变得更易读或更简单。”</p>

<p>“但是我们决定使用Mockito进行所有测试！”</p>

<p>我：“……”</p>

<p>后来我碰到他，他自豪地说，他已经设法用Mockito写了测试。我明白让测试代码正常运行的心理满足感，但尽管如此，这种解决方案让我难过。</p>

<h3 id="另一个例子">另一个例子</h3>

<p>我加入的某个开发团队，他们对新应用程序的高代码覆盖率以及对BDD（行为驱动设计）的新发现感到兴奋。查看代码，可以发现如下的Cucumber测试：</p>

<p><img src="/uploads/cucumber-test.png" alt="cucumber-test"></p>

<p>如果你以前使用过Cucumber，你就不会震惊于它所需的支持代码的数量：</p>

<p><img src="/uploads/cucumber-support.png" alt="cucumber-support"></p>

<p><img src="/uploads/cucumber-support2.png" alt="cucumber-support2"></p>

<p>和所有要测试的代码：</p>

<p><img src="/uploads/cucumber-code.png" alt="cucumber-code"></p>

<p>是的，一个简单的地图查找。我和这个开发者有足够的信任去直言不讳地说，“这是在浪费时间。”</p>

<p>“但我的老板希望我能为所有的类写测试，”他回答。</p>

<p>“代价是什么？”</p>

<p>“费用？”</p>

<p>“无论如何，这些测试与BDD无关。”</p>

<p>“我知道，但是我们决定使用Cucumber进行所有测试”</p>

<p>我：“……”</p>

<p>我明白按照自己意愿改造工具的心理满足感，但尽管如此，这种解决方案让我难过。</p>

<h3 id="悲剧在哪里？">悲剧在哪里？</h3>

<p>悲剧是两位聪明的开发者（我需要带他们去团队面试）浪费时间写那种测试，测试是毫无意义的，但需要后来的IG开发者维护。</p>

<p>悲剧是不使用正确的工具，因为没有特别好的理由，我们决定坚持不懈地使用错误的工具。</p>

<p>悲剧是一旦某个“良好实践”成为主流，我们似乎就忘记它是怎么来的，它的好处是什么，最主要的是，使用它的代价是什么。</p>

<p>如果我们只是机械地应用它而没有太多的思考，这通常意味着我们最终得到最平庸的结果，失去大部分的好处，但支付所有（甚至更多）的成本。根据我的经验，编写好的单元测试并非易事。</p>

<h3 id="那么100-的代码覆盖率值得追求吗？">那么100%的代码覆盖率值得追求吗？</h3>

<p>是的，每个人都应该实现它……在一个项目中。我认为你必须用极端的手段去了解限制是什么。</p>

<p>我们已经有了一个极端的大量经验：0个单元测试的项目，所以我们知道在这上面工作的痛苦。我们通常缺乏的是在另一个极端的经验：强制100%代码覆盖率和一切都是TDD的项目。单元测试（尤其是测试先行方法）是一个非常好的实践，但我们应该学习哪些测试是有用的，哪些是适得其反的。</p>

<p>要记住没有什么是免费的，没有什么是银弹。使用工具前请停下来想一想。</p>

<h4 id="关于作者">关于作者</h4>

<p>Daniel Lebrero在IG的大数据团队担任技术架构师。拥有超过15年的Java经验和4年的Clojure经验，他现在是函数式编程的大力倡导者。可以在<a href="https://twitter.com/DanLebrero">Twitter</a>，<a href="https://www.linkedin.com/in/daniel-lebrero-4729906">LinkedIn</a>或者他的个人<a href="http://danlebrero.com/">博客</a>找到他。</p>
]]></content>
  </entry>
  
</feed>
